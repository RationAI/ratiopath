{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RatioPath","text":"<p>Welcome to the RatioPath documentation! This is your go-to resource for understanding and utilizing the RatioPath library for histopathology tasks. Whether you're a researcher, clinician, or developer, you'll find valuable information here to help you get started and make the most of our tools.</p> <p>Learn API Reference</p>"},{"location":"learn/get-started/installation/","title":"Installation","text":"<p>This guide walks you through installing the RatioPath library and its required binary dependencies for working with whole-slide images (WSI).</p> <p>Python Requirement</p> <p>You need Python 3.11 or newer to run ratiopath.</p>"},{"location":"learn/get-started/installation/#binary-dependencies","title":"Binary Dependencies","text":""},{"location":"learn/get-started/installation/#openslide","title":"OpenSlide","text":"<p>OpenSlide is required to read most WSI formats. You must install the native library before (or alongside) the Python package.</p>"},{"location":"learn/get-started/installation/#linux-debian-ubuntu","title":"Linux (Debian / Ubuntu)","text":"<pre><code>sudo apt-get update\nsudo apt-get install -y openslide-tools\n</code></pre>"},{"location":"learn/get-started/installation/#macos-homebrew","title":"macOS (Homebrew)","text":"<pre><code>brew update\nbrew install openslide\n</code></pre>"},{"location":"learn/get-started/installation/#windows","title":"Windows","text":"<p>Download and install the OpenSlide binaries.</p> Alternative: Python wheels <p>If you cannot install system packages, you can try using <code>openslide-bin</code> from PyPI.</p> <pre><code>pip install openslide-bin\n</code></pre> <p>Warning</p> <p>This method bundles the OpenSlide library and is not compatible with <code>pyvips</code>. Avoid using them together.</p>"},{"location":"learn/get-started/installation/#install-the-python-package","title":"Install the Python Package","text":"<p>Choose your preferred package manager to install the library.</p> uvpippdm <pre><code>uv add ratiopath\n</code></pre> <pre><code>pip install ratiopath\n</code></pre> <pre><code>pdm add ratiopath\n</code></pre>"},{"location":"learn/get-started/quick-start/","title":"Quick Start","text":"<p>Get from whole\u2011slide images to enriched tile metadata in minutes.</p>"},{"location":"learn/get-started/quick-start/#install","title":"Install","text":"<pre><code>pip install \"ratiopath\"\n</code></pre>"},{"location":"learn/get-started/quick-start/#minimal-pipeline","title":"Minimal Pipeline","text":"<pre><code>from ratiopath.ray import read_slides\nfrom ratiopath.tiling import grid_tiles\n\nslides = read_slides(\"data\", mpp=0.25, tile_extent=1024, stride=960)\n\ndef tiling(row):\n    return [\n        yield {\n            \"slide_id\": row[\"id\"],\n            \"tile_x\": x,\n            \"tile_y\": y,\n            \"level\": row[\"level\"],\n        }\n    for x, y in grid_tiles(\n        (row[\"extent_x\"], row[\"extent_y\"]),\n        (row[\"tile_extent_x\"], row[\"tile_extent_y\"]),\n        (row[\"stride_x\"], row[\"stride_y\"]),\n        last=\"keep\",\n    )\n    ]\n\n\ntiles = slides.flat_map(tiling)\ntiles.show(5)\n</code></pre>"},{"location":"learn/get-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Build the full tiling pipeline: Tiling Tutorial</li> <li>Add annotation coverage: Annotation Coverage</li> <li>Add overlays: Overlay Coverage</li> </ul>"},{"location":"learn/get-started/quick-start/#tips","title":"Tips","text":"<ul> <li>Use .stats() after an action to inspect performance.</li> <li>Repartition before expensive pixel reads.</li> <li>Keep slide metadata separate; avoid duplication.</li> </ul> <p>Ready? Jump to the Tiling Tutorial.</p>"},{"location":"learn/get-started/quick-start/annotations/","title":"Adding Annotation Coverage to Tiles","text":"<p>This tutorial shows you how to enrich your tiling pipeline with annotation data\u2014such as regions of interest, cancer boundaries, or other expert-marked areas. You\u2019ll learn how to parse annotation files, compute coverage for each tile, and add this information to your dataset using <code>ratiopath</code>.</p>"},{"location":"learn/get-started/quick-start/annotations/#step-1-understanding-annotation-coverage","title":"Step 1: Understanding Annotation Coverage","text":"<p>Annotation coverage quantifies how much of a tile overlaps with annotated regions (e.g., cancerous tissue). This is useful for downstream analysis, training machine learning models, or filtering tiles based on biological relevance.</p>"},{"location":"learn/get-started/quick-start/annotations/#step-2-parsing-annotation-files","title":"Step 2: Parsing Annotation Files","text":"<p>To associate tiles with annotation data, you first need to parse the annotation files. <code>ratiopath</code> provides parsers for common formats such as ASAP XML and GeoJSON.</p> <pre><code>from ratiopath.parsers import ASAPParser\n\nannotation_path = row[\"path\"].replace(\".mrxs\", \".xml\")\nparser = ASAPParser(annotation_path)\nannotations = list(parser.get_polygons(name=\"...\", part_of_group=\"...\"))\n</code></pre> <ul> <li>Replace <code>.mrxs</code> with your slide file extension as needed.</li> <li>Use appropriate parser for your annotation format.</li> <li>Note: The <code>name</code> and <code>part_of_group</code> arguments are regular expressions used to filter annotations based on their <code>Name</code> and <code>PartOfGroup</code> attributes.</li> </ul>"},{"location":"learn/get-started/quick-start/annotations/#step-3-computing-tile-coverage","title":"Step 3: Computing Tile Coverage","text":"<p>For each tile, define its region of interest (ROI) as a polygon. Then, calculate the fraction of the tile area covered by annotation polygons. Note: In this example, the ROI is set to cover the entire tile, but you can use any geometry inside the tile as the ROI (e.g., a subregion, mask, or shape of interest). The ROI is always defined relative to the tile's coordinate system.</p> <pre><code>from shapely import Polygon\n\nroi = Polygon([\n    (0, 0),\n    (row[\"tile_extent_x\"], 0),\n    (row[\"tile_extent_x\"], row[\"tile_extent_y\"]),\n    (0, row[\"tile_extent_y\"]),\n])\n</code></pre>"},{"location":"learn/get-started/quick-start/annotations/#step-4-attaching-coverage-to-tile-metadata","title":"Step 4: Attaching Coverage to Tile Metadata","text":"<p>Use the <code>tile_annotations</code> function to compute which annotation polygons overlap with the tile and return their intersection polygons. Add the coverage value to each tile row.</p> <pre><code>from ratiopath.tiling import tile_annotations\n\ndef tiling_with_annotations(row: dict[str, Any]) -&gt; list[dict[str, Any]]:\n    annotation_path = row[\"path\"].replace(\".mrxs\", \".xml\")\n    parser = ASAPParser(annotation_path)\n    annotations = list(parser.get_polygons(name=\"...\", part_of_group=\"...\"))\n\n    roi = Polygon([\n        (0, 0),\n        (row[\"tile_extent_x\"], 0),\n        (row[\"tile_extent_x\"], row[\"tile_extent_y\"]),\n        (0, row[\"tile_extent_y\"]),\n    ])\n\n    coordinates = np.array(list(\n        grid_tiles(\n            slide_extent=(row[\"extent_x\"], row[\"extent_y\"]),\n            tile_extent=(row[\"tile_extent_x\"], row[\"tile_extent_y\"]),\n            stride=(row[\"stride_x\"], row[\"stride_y\"]),\n            last=\"keep\",\n        )\n    ))\n    return [\n        {\n            \"tile_x\": coordinates[i, 0],\n            \"tile_y\": coordinates[i, 1],\n            \"path\": row[\"path\"],\n            \"slide_id\": row[\"id\"],\n            \"level\": row[\"level\"],\n            \"tile_extent_x\": row[\"tile_extent_x\"],\n            \"tile_extent_y\": row[\"tile_extent_y\"],\n            \"coverage\": polygon.area / roi.area,\n        }\n        for i, polygon in enumerate(\n            tile_annotations(\n                annotations,\n                roi,\n                coordinates,\n                row[\"downsample\"],\n            )\n        )\n    ]\n</code></pre> <ul> <li>Each output row contains tile coordinates, metadata, and coverage value.</li> </ul>"},{"location":"learn/get-started/quick-start/annotations/#step-5-integrating-with-the-pipeline","title":"Step 5: Integrating with the Pipeline","text":"<p>Apply the annotation coverage function to your tiles dataset using Ray Data\u2019s <code>flat_map</code> or <code>map_batches</code>:</p> <pre><code>tiles = slides.flat_map(tiling_with_annotations)\n</code></pre> <p>You can now filter, group, or analyze tiles based on their annotation coverage.</p>"},{"location":"learn/get-started/quick-start/annotations/#notes-and-next-steps","title":"Notes and Next Steps","text":"<ul> <li>The <code>ASAPParser</code> can be replaced with other parsers (e.g., <code>GeoJSONParser</code>) depending on your annotation format.</li> <li>You can extend this approach to compute coverage for multiple annotation classes, or other metrics (e.g., distance to nearest annotation).</li> </ul> <p>By adding annotation coverage, your pipeline produces richer tile metadata, enabling more targeted downstream workflows such as supervised learning, tissue quantification, or quality control.</p>"},{"location":"learn/get-started/quick-start/overlays/","title":"Attaching Overlay Data to Image Tiles","text":"<p>This tutorial demonstrates how to enrich your primary tile dataset with corresponding image patches (overlays) from a secondary whole-slide image (WSI), such as a tissue mask or a heatmap. You will use Ray Data's batch processing with the <code>tile_overlay</code> and <code>tile_overlay_overlap</code> functions from the <code>ratiopath</code> library.</p>"},{"location":"learn/get-started/quick-start/overlays/#step-1-understanding-overlay-tiling-and-coordinate-system","title":"Step 1: Understanding Overlay Tiling and Coordinate System","text":"<p>Overlays (e.g., tissue masks) are often image files that are aligned with the original WSI but frequently have a different physical resolution ($\\mu m/px$). The <code>ratiopath</code> functions, <code>tile_overlay</code> and <code>tile_overlay_overlap</code>, automatically handle these resolution differences and apply the necessary scaling to adjust tile coordinates before reading the overlay patches.</p>"},{"location":"learn/get-started/quick-start/overlays/#essential-tile-overlay-metadata","title":"Essential Tile Overlay Metadata","text":"<p>Both presented functions, <code>tile_overlay</code> and <code>tile_overlay_overlap</code>, are Ray's User Defined Function Expressions (<code>UDFExpr</code>) that process batches of data provided as column expressions. Both functions further require a Region of Interest (ROI) which defines the area of interets relative to each provided underlaying tile. The ROI must be define in the underlying tile's space (physical resolution). There are no limits for the shape of the ROI it can be an arbitrary polygon, neither the size, it may exceed the underlying tile. The ROIs that may exceed beyond the overlay image bounds are automatically clipped to the overlay image bounds.</p> <p>To correctly locate, scale, and extract the corresponding overlay patch, the processing function require following metadata.</p> Column Data Type Description <code>tile_x</code>, <code>tile_y</code> <code>int</code> Top-left pixel coordinates of the tile in the primary slide's coordinate system. <code>tile_extent_x</code>, <code>tile_extent_y</code> <code>int</code> Width/Height of the tile in the primary slide's coordinate system. <code>mpp_x</code>, <code>mpp_y</code> <code>float</code> Physical resolution ($\\mu m/px$) of the level used for the tile extraction. <code>overlay_path</code> <code>str</code> File path to the overlay WSI."},{"location":"learn/get-started/quick-start/overlays/#step-2-attaching-the-overlay-patches-tile_overlay","title":"Step 2: Attaching the Overlay Patches (<code>tile_overlay</code>)","text":"<p>First, assume you have prepared a Ray Dataset of tiles (<code>tiles</code>) following a quick-start guide, where each record contains a <code>path</code> column (the primary WSI file path).</p>"},{"location":"learn/get-started/quick-start/overlays/#21-augmenting-with-overlay-path","title":"2.1 Augmenting with Overlay Path","text":"<p>You must augment the tile dataset to include a column with the file path to the overlay WSI that corresponds to each tile.</p> <pre><code># Follow the tutorial in Tiling Quick Start to prepare the Ray Dataset of tiles\nslides = ...\ntiles = ...\n\ndef add_overlay_path(batch: dict) -&gt; dict:\n    \"\"\"Adds the overlay path for each tile in the batch.\"\"\"\n    # Example: Replace the WSI extension with the mask file extension\n    batch[\"tissue_mask_path\"] = batch[\"path\"].str.replace(\".mrxs\", \"_tissue_mask.tiff\")\n    return batch\n\ntiles = tiles.map_batches(add_overlay_path)\n</code></pre>"},{"location":"learn/get-started/quick-start/overlays/#22-define-the-region-of-interest-roi","title":"2.2 Define the Region of Interest (ROI)","text":"<p>For this example, we will use a simple rectangular ROI that corresponds to the center view of each tile with half the width and height.</p> <pre><code>from shapely.geometry import box\n\n\n# Assuming the tile size is 512x512 pixels\nroi = box(128, 128, 384, 384) # A box from (128,128) to (384,384)\n</code></pre>"},{"location":"learn/get-started/quick-start/overlays/#23-extracting-overlay-patches","title":"2.3 Extracting Overlay Patches","text":"<p>We can now use the <code>tile_overlay</code> function to extract the overlay patches corresponding to each tile. We will store the extracted overlay patches in a new column called <code>tissue_overlay</code>.</p> <pre><code>from ratiopath.tiling import tile_overlay\nfrom ray.data.expressions import col\n\n\ntile_with_overlay = tiles.with_column(\n    \"tissue_overlay\",  # New column name for the overlay patch\n    tile_overlay(\n        roi=roi,\n        overlay_path=col(\"tissue_mask_path\"),\n        tile_x=col(\"tile_x\"),\n        tile_y=col(\"tile_y\"),\n        mpp_x=col(\"mpp_x\"),\n        mpp_y=col(\"mpp_y\"),\n    ),\n    num_cpus=1,\n    memory=4 * 1024**3,\n)\n</code></pre> <p>The <code>tiles_with_overlays</code> dataset will now include a new column, <code>tissue_overlay</code>, containing the raw overlay image patches corresponding to each tile. For optimization purposes, the overlay patches are of the shape of the bounding box of the provided ROI. Unfortunately, at the moment we cannot use masked arrays directly in Ray Dataset. So instead of a numpy masked array, we provide the data and the mask as 2 separate arrays. The mask indicates which pixels are inside the ROI and which are outside.</p>"},{"location":"learn/get-started/quick-start/overlays/#step-3-computing-overlay-overlapcoverage-tile_overlay_overlap","title":"Step 3: Computing Overlay Overlap/Coverage (<code>tile_overlay_overlap</code>)","text":"<p>Instead of retrieving the raw image patch, you can compute the pixel ratio for every unique value in the resulting overlay patch, which is useful for filtering tiles based on content (e.g., how much tissue is present). The setup is similar to the previous step.</p> <pre><code>from ratiopath.tiling import tile_overlay_overlap\n\n\ntissue_tiles = tiles.with_column(\n    \"tissue_overlap\",  # New column name for the overlay patch\n    tile_overlay_overlap(\n        roi=roi,\n        overlay_path=col(\"tissue_mask_path\"),\n        tile_x=col(\"tile_x\"),\n        tile_y=col(\"tile_y\"),\n        mpp_x=col(\"mpp_x\"),\n        mpp_y=col(\"mpp_y\"),\n    ),\n    num_cpus=1,\n    memory=4 * 1024**3,\n)\n</code></pre>"},{"location":"learn/get-started/quick-start/overlays/#post-processing-the-overlap-data","title":"Post-Processing the Overlap Data","text":"<p>The new column <code>tissue_mask_overlap</code> contains a dictionary for each tile, mapping unique pixel values (e.g., 0, 1, 255) in the overlay to their area coverage (as a fraction summing to 1). Due to PyArrow's dictionary limitations, which is used by Ray for storing the data, the keys are strings and the keys are shared across all rows. Missing keys are filled with <code>None</code>. You can easily post-process this to extract coverage of a specific class (e.g., the foreground tissue, often value <code>255</code>):</p> <pre><code>def extract_foreground_coverage(tile: dict) -&gt; dict:\n    \"\"\"Extracts the foreground coverage (value 255) from the overlap dictionary.\"\"\"\n    # Use .get(255, 0.0) to safely retrieve the value, defaulting to 0.0 if not present\n    tile[\"tissue_coverage\"] = tile[\"tissue_mask_overlap\"].get('255', 0.0)\n    return tile\n\ntiles_with_tissue_coverage = tiles_with_overlap.map(extract_foreground_coverage).filter(\n    lambda tile: tile[\"tissue_coverage\"] &gt;= 0.5  # Keep tiles with at least 50% tissue\n)\n</code></pre>"},{"location":"learn/get-started/quick-start/overlays/#notes-and-implementation-details","title":"Notes and Implementation Details","text":""},{"location":"learn/get-started/quick-start/overlays/#resolution-scaling-mu-mpx","title":"Resolution Scaling ($\\mu m/px$)","text":"<p>The module's core functionality relies on calculating the scaling factor ($S_x$, $S_y$) required to map the tile coordinates from the primary slide's resolution ($M_{slide}$) to the overlay's resolution ($M_{overlay}$):</p> <p>$$S_{x} = \\frac{M_{slide, x}}{M_{overlay, x}}$$</p> <p>This factor is then applied to the tile's coordinates and dimensions. To ensure precise pixel addressing, the resulting floating-point values are rounded to the nearest integer:</p> <p>$$\\text{New_Coordinate} = \\lfloor (\\text{Old_Coordinate} \\times S) + 0.5 \\rfloor$$</p>"},{"location":"learn/get-started/quick-start/overlays/#backend-handling","title":"Backend Handling","text":"<p>The functions automatically detect the overlay file type (e.g., OpenSlide format or OME-TIFF) and use the appropriate backend (<code>_read_openslide_overlay</code> or <code>_read_tifffile_overlay</code>) for efficient access to the overlay image pyramid, abstracting the details from the user.</p>"},{"location":"learn/get-started/quick-start/tiling/","title":"Building a Tiling Pipeline","text":"<p>You will build a simple but efficient and scalable tiling pipeline for histopathology slides. This tutorial does not assume any existing knowledge of parallel processing frameworks. We will use Ray Data and explain the necessary concepts as we go. The techniques you'll learn are fundamental to building scalable data processing workflows with <code>ratiopath</code>.</p> <p>This tutorial is divided into several sections:</p> <ul> <li>Setup will give you a starting point to follow the tutorial.</li> <li>Overview will teach you the fundamentals of processing slides with <code>ratiopath</code> and Ray.</li> <li>Building the Pipeline will guide you through the most common techniques in a tiling workflow.</li> </ul>"},{"location":"learn/get-started/quick-start/tiling/#what-are-you-building","title":"What are you building?","text":"<p>In this tutorial, you'll build a pipeline that reads whole-slide images, generates a grid of tiles, filters out background tiles, and saves the results as a Parquet file.</p> <p>You can see what it will look like when you\u2019re finished here:</p> <pre><code>from typing import Any\n\nfrom ray.data.expressions import col\n\nfrom ratiopath.ray import read_slides\nfrom ratiopath.tiling import grid_tiles, read_slide_tiles\nfrom ratiopath.tiling.utils import row_hash\n\n\ndef tiling(row: dict[str, Any]) -&gt; list[dict[str, Any]]:\n    return [\n        {\n            \"tile_x\": x,\n            \"tile_y\": y,\n            \"path\": row[\"path\"],\n            \"slide_id\": row[\"id\"],\n            \"level\": row[\"level\"],\n            \"tile_extent_x\": row[\"tile_extent_x\"],\n            \"tile_extent_y\": row[\"tile_extent_y\"],\n        }\n        for x, y in grid_tiles(\n            slide_extent=(row[\"extent_x\"], row[\"extent_y\"]),\n            tile_extent=(row[\"tile_extent_x\"], row[\"tile_extent_y\"]),\n            stride=(row[\"stride_x\"], row[\"stride_y\"]),\n            last=\"keep\",\n        )\n    ]\n\n\nif __name__ == \"__main__\":\n    slides = read_slides(\"data\", mpp=0.25, tile_extent=1024, stride=1024 - 64)\n\n    slides = slides.map(row_hash, num_cpus=0.1, memory=128 * 1024**2)\n    slides.write_parquet(\"slides\")\n\n    tiles = slides.flat_map(tiling, num_cpus=0.2, memory=128 * 1024**2).repartition(\n        target_num_rows_per_block=128\n    )\n\n    tissue_tiles = tiles.with_column(\n        \"tile\",\n        read_slide_tiles(\n            col(\"path\"),\n            col(\"tile_x\"),\n            col(\"tile_y\"),\n            col(\"tile_extent_x\"),\n            col(\"tile_extent_y\"),\n            col(\"level\"),\n        ),\n        num_cpus=1,\n        memory=4 * 1024**3,\n    ).filter(lambda row: row[\"tile\"].std() &gt; 8)\n\n    tissue_tiles = tissue_tiles.drop_columns(\n        [\"tile\", \"path\", \"level\", \"tile_extent_x\", \"tile_extent_y\"]\n    )\n\n    tissue_tiles.write_parquet(\"tiles\")\n</code></pre> <p>If the code doesn't make sense to you yet, don't worry! We\u2019ll break it down and reconstruct it piece by piece.</p>"},{"location":"learn/get-started/quick-start/tiling/#setup","title":"Setup","text":"<p>Before you start, make sure you have <code>ratiopath</code> installed. You will also need a directory with some sample whole-slide images (<code>.svs</code>, <code>.tif</code>, <code>.ndpi</code>, <code>.ome.tif</code>, ...). For this tutorial, we'll assume they are in a folder named <code>data/</code>.</p>"},{"location":"learn/get-started/quick-start/tiling/#overview","title":"Overview","text":"<p>Now that you're set up, let's get an overview of ratiopath!</p>"},{"location":"learn/get-started/quick-start/tiling/#processing-slides-as-a-table","title":"Processing Slides as a Table","text":"<p>Instead of \"open this giant image and loop over pixels,\" we're going to treat our collection of slides as a table of metadata. Each row represents a slide, with columns for its path, dimensions, resolution, and the tile size you want to use.</p> <p>Why care? Because metadata is tiny. Moving metadata through the cluster is cheap; reading gigapixel tiles is not. We defer real I/O until just before we need pixels.</p>"},{"location":"learn/get-started/quick-start/tiling/#parallel-processing-with-ray-data","title":"Parallel Processing with Ray Data","text":"<p>Ray Data is a library for scaling data processing. It takes your table of slides, splits it into parallel blocks, and runs your processing steps on multiple CPU cores.</p> <p></p> <p>You just need to define the work to be done on each row (or a batch of rows), and Ray handles the rest. We'll use a few key methods:</p> <ul> <li><code>map()</code>: Apply a function to each row.</li> <li><code>flat_map()</code>: Apply a function that can return multiple output rows for each input row.</li> <li><code>filter()</code>: Remove rows based on a condition.</li> <li><code>map_batches()</code>: Apply a function to a batch of rows at once.</li> <li><code>with_column()</code>: Add a new column to the dataset.</li> </ul> <p>Lazy Execution</p> <p>When you call a method like <code>map()</code> or <code>filter()</code>, Ray doesn't actually do anything yet. It just builds an internal logical plan\u2014a recipe of what you want to do (<code>Read -&gt; Map -&gt; FlatMap...</code>). The work only starts when you call an action like <code>write_parquet()</code> or <code>count()</code>. This \"lazy\" approach allows Ray to optimize the entire workflow before running it. You can even inspect the plan and performance stats with <code>dataset.stats()</code> after an action.</p>"},{"location":"learn/get-started/quick-start/tiling/#building-the-pipeline","title":"Building the Pipeline","text":"<p>Let's get started. This is where you'll spend the rest of the tutorial.</p>"},{"location":"learn/get-started/quick-start/tiling/#step-1-reading-slide-metadata","title":"Step 1: Reading Slide Metadata","text":"<p>First, you'll create a <code>Dataset</code> from your slides. A <code>Dataset</code> is just Ray's name for a table that can be processed in parallel. Each row in our <code>Dataset</code> will correspond to a single slide.</p> <p><code>ratiopath</code> provides a custom <code>read_slides</code> method that plugs directly into Ray. You tell it where your slides are (<code>\"data\"</code>), and what resolution you want to work with. Here, we're asking for a resolution where one pixel is about <code>0.25</code> micrometers (<code>mpp=0.25</code>). The datasource will automatically find the best magnification level in each slide file to match this.</p> <p>You also provide <code>tile_extent</code> (the size of your tiles, e.g., 1024x1024 pixels) and <code>stride</code> (how far to move before starting the next tile). These are added as metadata to each row, ready for the tiling step later.</p> <pre><code>from ratiopath.ray import read_slides\n\nslides = read_slides(\"data\", mpp=0.25, tile_extent=1024, stride=1024 - 64)\n</code></pre> <p>This returns a <code>Dataset</code> where each row is a dictionary holding the metadata for one slide. It looks something like this:</p> <pre><code>{\n  \"path\": \"/abs/path/slide1.svs\",\n  \"extent_x\": 84320,\n  \"extent_y\": 61120,\n  \"tile_extent_x\": 1024,\n  \"tile_extent_y\": 1024,\n  \"stride_x\": 960,\n  \"stride_y\": 960,\n  \"mpp_x\": 0.25,\n  \"mpp_y\": 0.25,\n  \"level\": 2,\n  \"downsample\": 4.0\n}\n</code></pre>"},{"location":"learn/get-started/quick-start/tiling/#step-2-creating-unique-slide-ids","title":"Step 2: Creating Unique Slide IDs","text":"<p>Next, you'll give each slide a unique ID. Why? If you process the same slide with different parameters (like different tile sizes), you'll want a consistent way to identify which slide a tile came from. We'll do this by hashing the slide's metadata.</p> <p>You'll use <code>.map()</code> to apply the <code>row_hash</code> function to every row in your <code>Dataset</code>. Then, you'll save this slide-level table to a Parquet file. This is a good practice because you want to store this metadata only once for all the tiles in a slide.</p> <pre><code>from ratiopath.tiling.utils import row_hash\n\nslides = slides.map(row_hash, num_cpus=0.1, memory=128 * 1024**2)\nslides.write_parquet(\"slides\")\n</code></pre> <p>Our First Action!</p> <p><code>write_parquet()</code> is our first action. Only now does Ray actually execute the plan (<code>Read -&gt; Map</code>). Before this call, nothing had run.</p>"},{"location":"learn/get-started/quick-start/tiling/#step-3-expand-slides-into-tile-coordinates","title":"Step 3: Expand Slides into Tile Coordinates","text":"<p>Now it's time to generate the grid of tiles for each slide. You'll use <code>flat_map()</code> because each slide row will \"explode\" into many tile rows.</p> <p>First, define a <code>tiling</code> function. This function takes a slide row (which contains all the metadata) and uses <code>grid_tiles</code> to generate a list of <code>(x, y)</code> coordinates for the top-left corner of each tile. Each coordinate becomes a new row, and we also copy relevant parent slide's metadata into it.</p> <pre><code>from typing import Any\nfrom ratiopath.tiling import grid_tiles\n\ndef tiling(row: dict[str, Any]) -&gt; list[dict[str, Any]]:\n    return [\n        {\n            \"tile_x\": x,\n            \"tile_y\": y,\n            \"path\": row[\"path\"],\n            \"slide_id\": row[\"id\"],\n            \"level\": row[\"level\"],\n            \"tile_extent_x\": row[\"tile_extent_x\"],\n            \"tile_extent_y\": row[\"tile_extent_y\"],\n        }\n        for x, y in grid_tiles(\n            slide_extent=(row[\"extent_x\"], row[\"extent_y\"]),\n            tile_extent=(row[\"tile_extent_x\"], row[\"tile_extent_y\"]),\n            stride=(row[\"stride_x\"], row[\"stride_y\"]),\n            last=\"keep\",\n        )\n    ]\n\ntiles = slides.flat_map(tiling, num_cpus=0.2, memory=128 * 1024**2)\n</code></pre> <p>After <code>flat_map</code>, all tiles from a single slide are likely in the same data block. To get better parallelism for the next, more intensive step, you should <code>repartition</code> the dataset. This shuffles the rows (our tiles) so they are more evenly distributed across many smaller blocks, allowing Ray to spread the work across more CPU cores.</p> <pre><code>tiles = tiles.repartition(target_num_rows_per_block=128)\n</code></pre> <p>Choosing target_num_rows_per_block</p> <p>Aim for blocks large enough to amortize scheduling overhead (hundreds\u2013thousands of rows) but small enough to balance across cores and fit in memory when you later attach pixel arrays.</p>"},{"location":"learn/get-started/quick-start/tiling/#step-4-reading-and-filtering-tiles","title":"Step 4: Reading and Filtering Tiles","text":"<p>So far, you've only worked with coordinates. Now, you'll read the actual image data for each tile and filter out the ones that don't contain tissue.</p> <p>The <code>read_slide_tiles</code> function reads the corresponding tile regions from the original slide file and adds it to the dataset as a NumPy array. The function is designed to work efficiently with batches of tiles. The inputs are columns from the <code>tiles</code> dataset, specified using Ray's column expressions (<code>col(\"column_name\")</code>). </p> <pre><code>from ray.data.expressions import col\n\nfrom ratiopath.tiling import read_slide_tiles\n\n\ntiles_with_pixels = tiles.with_column(\n    \"tile\",  # Name of the new column to add.\n    read_slide_tiles(\n        col(\"path\"),\n        col(\"tile_x\"),\n        col(\"tile_y\"),\n        col(\"tile_extent_x\"),\n        col(\"tile_extent_y\"),\n        col(\"level\"),\n    ),\n    num_cpus=1,  # Reading and decoding images is CPU-heavy.\n    memory=4 * 1024**3,  # Give Ray a hint about how much memory this task needs.\n)\n</code></pre> <p>This function is most efficient when the batch of tiles belongs to a single slide and the tiles are stored sequentially. This allows it to maximize cache usage and minimize repeated I/O operations.</p> <p>Next, you'll define a simple <code>filter_tissue</code> function. For this tutorial, we'll use a basic but effective heuristic: if the standard deviation of a tile's pixel values is above a certain threshold, we assume it contains tissue. Tiles that are mostly one color (like the white background) will have a very low standard deviation.</p> <p>You then use <code>.filter()</code> to apply this function and keep only the rows that return <code>True</code>.</p> <pre><code>tissue_tiles = tiles_with_pixels.filter(lambda row: row[\"tile\"].std() &gt; 8)\n</code></pre>"},{"location":"learn/get-started/quick-start/tiling/#step-5-saving-the-results","title":"Step 5: Saving the Results","text":"<p>You're almost there! The final step is to write the filtered tile information to disk. The image data itself (<code>row[\"tile\"]</code>) can make the dataset very large, and you probably don't need to save the raw pixels. Additionally, you can omit redundant metadata (like <code>tile_extent</code>) that is already saved in the <code>slides</code> Parquet dataset.</p> <p>So, you'll drop columns that are not needed for the final output.</p> <pre><code>tissue_tiles = tissue_tiles.drop_columns(\n    [\"tile\", \"path\", \"level\", \"tile_extent_x\", \"tile_extent_y\"]\n)\n\ntissue_tiles.write_parquet(\"tiles\")\n</code></pre>"},{"location":"learn/get-started/quick-start/tiling/#wrapping-up","title":"Wrapping up","text":"<p>Congratulations! You've just built a scalable tiling pipeline. You now have:</p> <ul> <li><code>slides/</code>: A Parquet dataset where each row contains the metadata and unique ID for a whole-slide image.</li> <li><code>tiles/</code>: A Parquet dataset where each row represents a single tissue tile, with its parent slide's ID and its coordinates.</li> </ul> <p>You've learned how to think about slide processing in a tabular way, how to use Ray Data to parallelize your work, and how to build a pipeline step-by-step.</p>"},{"location":"reference/openslide/","title":"ratiopath.openslide.OpenSlide","text":"<p>               Bases: <code>OpenSlide</code></p> <p>A wrapper around the OpenSlide library to provide additional functionality.</p> Source code in <code>ratiopath/openslide.py</code> <pre><code>class OpenSlide(openslide.OpenSlide):\n    \"\"\"A wrapper around the OpenSlide library to provide additional functionality.\"\"\"\n\n    def closest_level(self, mpp: float | tuple[float, float]) -&gt; int:\n        \"\"\"Finds the closest slide level to match the desired MPP.\n\n        This method compares the desired MPP (\u00b5m/px) with the MPP of the\n        available levels in the slide and selects the level with the closest match.\n\n        Args:\n            mpp: The desired \u00b5m/px value.\n\n        Returns:\n            The index of the level with the closest \u00b5m/px resolution to the desired value.\n        \"\"\"\n        scale_factor = np.mean(\n            np.asarray(mpp)\n            / np.array(\n                [\n                    float(self.properties[PROPERTY_NAME_MPP_X]),\n                    float(self.properties[PROPERTY_NAME_MPP_Y]),\n                ]\n            )\n        )\n\n        return np.abs(np.asarray(self.level_downsamples) - scale_factor).argmin().item()\n\n    def slide_resolution(self, level: int) -&gt; tuple[float, float]:\n        \"\"\"Returns the resolution of the slide in \u00b5m/px at the given level.\n\n        Args:\n            level: The level of the slide to calculate the resolution.\n\n        Returns:\n            The [x, y] resolution of the slide in \u00b5m/px.\n        \"\"\"\n        slide_mpp_x = float(self.properties[PROPERTY_NAME_MPP_X])\n        slide_mpp_y = float(self.properties[PROPERTY_NAME_MPP_Y])\n\n        return (\n            slide_mpp_x * self.level_downsamples[level],\n            slide_mpp_y * self.level_downsamples[level],\n        )\n\n    def read_region_relative(\n        self, location: tuple[int, int], level: int, size: tuple[int, int]\n    ) -&gt; Image:\n        \"\"\"Reads a region from the slide with coordinates relative to the specified level.\n\n        This method adjusts the coordinates based on the level's downsampling factor\n        before reading the region from the slide.\n\n        Args:\n            location: The (x, y) coordinates at the specified level.\n            level: The level of the slide to read from.\n            size: The (width, height) of the region to read.\n\n        Returns:\n            The image of the requested region.\n        \"\"\"\n        downsample = self.level_downsamples[level]\n        location = (int(location[0] * downsample), int(location[1] * downsample))\n\n        return super().read_region(location, level, size)\n</code></pre>"},{"location":"reference/openslide/#ratiopath.openslide.OpenSlide.closest_level","title":"<code>closest_level(mpp)</code>","text":"<p>Finds the closest slide level to match the desired MPP.</p> <p>This method compares the desired MPP (\u00b5m/px) with the MPP of the available levels in the slide and selects the level with the closest match.</p> <p>Parameters:</p> Name Type Description Default <code>mpp</code> <code>float | tuple[float, float]</code> <p>The desired \u00b5m/px value.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The index of the level with the closest \u00b5m/px resolution to the desired value.</p> Source code in <code>ratiopath/openslide.py</code> <pre><code>def closest_level(self, mpp: float | tuple[float, float]) -&gt; int:\n    \"\"\"Finds the closest slide level to match the desired MPP.\n\n    This method compares the desired MPP (\u00b5m/px) with the MPP of the\n    available levels in the slide and selects the level with the closest match.\n\n    Args:\n        mpp: The desired \u00b5m/px value.\n\n    Returns:\n        The index of the level with the closest \u00b5m/px resolution to the desired value.\n    \"\"\"\n    scale_factor = np.mean(\n        np.asarray(mpp)\n        / np.array(\n            [\n                float(self.properties[PROPERTY_NAME_MPP_X]),\n                float(self.properties[PROPERTY_NAME_MPP_Y]),\n            ]\n        )\n    )\n\n    return np.abs(np.asarray(self.level_downsamples) - scale_factor).argmin().item()\n</code></pre>"},{"location":"reference/openslide/#ratiopath.openslide.OpenSlide.read_region_relative","title":"<code>read_region_relative(location, level, size)</code>","text":"<p>Reads a region from the slide with coordinates relative to the specified level.</p> <p>This method adjusts the coordinates based on the level's downsampling factor before reading the region from the slide.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>tuple[int, int]</code> <p>The (x, y) coordinates at the specified level.</p> required <code>level</code> <code>int</code> <p>The level of the slide to read from.</p> required <code>size</code> <code>tuple[int, int]</code> <p>The (width, height) of the region to read.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>The image of the requested region.</p> Source code in <code>ratiopath/openslide.py</code> <pre><code>def read_region_relative(\n    self, location: tuple[int, int], level: int, size: tuple[int, int]\n) -&gt; Image:\n    \"\"\"Reads a region from the slide with coordinates relative to the specified level.\n\n    This method adjusts the coordinates based on the level's downsampling factor\n    before reading the region from the slide.\n\n    Args:\n        location: The (x, y) coordinates at the specified level.\n        level: The level of the slide to read from.\n        size: The (width, height) of the region to read.\n\n    Returns:\n        The image of the requested region.\n    \"\"\"\n    downsample = self.level_downsamples[level]\n    location = (int(location[0] * downsample), int(location[1] * downsample))\n\n    return super().read_region(location, level, size)\n</code></pre>"},{"location":"reference/openslide/#ratiopath.openslide.OpenSlide.slide_resolution","title":"<code>slide_resolution(level)</code>","text":"<p>Returns the resolution of the slide in \u00b5m/px at the given level.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>The level of the slide to calculate the resolution.</p> required <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>The [x, y] resolution of the slide in \u00b5m/px.</p> Source code in <code>ratiopath/openslide.py</code> <pre><code>def slide_resolution(self, level: int) -&gt; tuple[float, float]:\n    \"\"\"Returns the resolution of the slide in \u00b5m/px at the given level.\n\n    Args:\n        level: The level of the slide to calculate the resolution.\n\n    Returns:\n        The [x, y] resolution of the slide in \u00b5m/px.\n    \"\"\"\n    slide_mpp_x = float(self.properties[PROPERTY_NAME_MPP_X])\n    slide_mpp_y = float(self.properties[PROPERTY_NAME_MPP_Y])\n\n    return (\n        slide_mpp_x * self.level_downsamples[level],\n        slide_mpp_y * self.level_downsamples[level],\n    )\n</code></pre>"},{"location":"reference/augmentations/estimate_stain_vectors/","title":"ratiopath.augmentations.estimate_stain_vectors","text":""},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.DAB","title":"<code>DAB = np.array([0.27, 0.57, 0.78])</code>  <code>module-attribute</code>","text":""},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.EOSIN","title":"<code>EOSIN = np.array([0.2159, 0.8012, 0.5581])</code>  <code>module-attribute</code>","text":""},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.HDAB","title":"<code>HDAB = np.array([HEMATOXYLIN, DAB, make_residual_stain(HEMATOXYLIN, DAB)], dtype=np.float32)</code>  <code>module-attribute</code>","text":""},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.HE","title":"<code>HE = np.array([HEMATOXYLIN, EOSIN, make_residual_stain(HEMATOXYLIN, EOSIN)], dtype=np.float32)</code>  <code>module-attribute</code>","text":""},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.HEMATOXYLIN","title":"<code>HEMATOXYLIN = np.array([0.65, 0.7, 0.29])</code>  <code>module-attribute</code>","text":""},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.discard_pixels","title":"<code>discard_pixels(od, min_stain, max_stain, gray_threshold=np.cos(0.15))</code>","text":"<p>Discard pixels based on optical density thresholds.</p> <p>Parameters:</p> Name Type Description Default <code>od</code> <code>ndarray</code> <p>A numpy array of optical densities for red, green, and blue channels.</p> required <code>min_stain</code> <code>float</code> <p>Minimum optical density threshold.</p> required <code>max_stain</code> <code>float</code> <p>Maximum optical density threshold.</p> required <code>gray_threshold</code> <code>float</code> <p>Threshold for excluding very gray pixels (default is cos(0.15)).</p> <code>cos(0.15)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array containing the filtered optical densities for red, green, and blue channels.</p> Source code in <code>ratiopath/augmentations/estimate_stain_vectors.py</code> <pre><code>def discard_pixels(\n    od: np.ndarray,\n    min_stain: float,\n    max_stain: float,\n    gray_threshold: float = np.cos(0.15),\n) -&gt; np.ndarray:\n    \"\"\"Discard pixels based on optical density thresholds.\n\n    Parameters:\n        od: A numpy array of optical densities for red, green, and blue channels.\n        min_stain: Minimum optical density threshold.\n        max_stain: Maximum optical density threshold.\n        gray_threshold: Threshold for excluding very gray pixels (default is cos(0.15)).\n\n    Returns:\n        A numpy array containing the filtered optical densities for red, green, and blue channels.\n    \"\"\"\n    keep_count = 0\n    max_stain_squared = max_stain * max_stain\n    sqrt3 = 1 / np.sqrt(3)\n\n    for i in range(len(od)):\n        r, g, b = od[i]\n        mag_squared = r * r + g * g + b * b\n        if (\n            mag_squared &gt; max_stain_squared\n            or r &lt; min_stain\n            or g &lt; min_stain\n            or b &lt; min_stain\n            or mag_squared &lt;= 0\n        ):\n            continue\n\n        # Exclude very gray pixels\n        if (r * sqrt3 + g * sqrt3 + b * sqrt3) / np.sqrt(mag_squared) &gt;= gray_threshold:\n            continue\n\n        od[keep_count] = np.array([r, g, b])\n        keep_count += 1\n\n    return od[:keep_count]\n</code></pre>"},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.estimate_stain_vectors","title":"<code>estimate_stain_vectors(image, default_stain_vectors, i0=256, min_stain=0.05, max_stain=1.0, alpha=0.01)</code>","text":"<p>Estimate stain vectors from an image using optical density transformation.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>A numpy array representing the input image.</p> required <code>default_stain_vectors</code> <code>ndarray</code> <p>A numpy array of default unit stain vectors.</p> required <code>i0</code> <code>int</code> <p>The intensity value for normalization.</p> <code>256</code> <code>min_stain</code> <code>float</code> <p>Minimum optical density threshold for discarding pixels.</p> <code>0.05</code> <code>max_stain</code> <code>float</code> <p>Maximum optical density threshold for discarding pixels.</p> <code>1.0</code> <code>alpha</code> <code>float</code> <p>The percentage of pixels to use for estimating the stain vectors (default is 0.01, which corresponds to 1%).</p> <code>0.01</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of estimated stain vectors.</p> References <p>Paper: A method for normalizing histology slides for quantitative analysis,     M Macenko, M Niethammer, JS Marron, D Borland, JT Woosley, G Xiaojun,     C Schmitt, NE Thomas, IEEE ISBI, 2009. dx.doi.org/10.1109/ISBI.2009.5193250</p> Source code in <code>ratiopath/augmentations/estimate_stain_vectors.py</code> <pre><code>def estimate_stain_vectors(\n    image: np.ndarray,\n    default_stain_vectors: np.ndarray,\n    i0: int = 256,\n    min_stain: float = 0.05,\n    max_stain: float = 1.0,\n    alpha: float = 0.01,\n) -&gt; np.ndarray:\n    \"\"\"Estimate stain vectors from an image using optical density transformation.\n\n    Parameters:\n        image: A numpy array representing the input image.\n        default_stain_vectors: A numpy array of default unit stain vectors.\n        i0: The intensity value for normalization.\n        min_stain: Minimum optical density threshold for discarding pixels.\n        max_stain: Maximum optical density threshold for discarding pixels.\n        alpha: The percentage of pixels to use for estimating the stain vectors\n            (default is 0.01, which corresponds to 1%).\n\n    Returns:\n        A numpy array of estimated stain vectors.\n\n    References:\n        Paper: A method for normalizing histology slides for quantitative analysis,\n            M Macenko, M Niethammer, JS Marron, D Borland, JT Woosley, G Xiaojun,\n            C Schmitt, NE Thomas, IEEE ISBI, 2009. dx.doi.org/10.1109/ISBI.2009.5193250\n    \"\"\"\n    od = -np.log10(np.maximum(image.reshape(-1, 3), 1) / i0)\n\n    od_hat = discard_pixels(od, min_stain, max_stain)\n\n    cov = np.cov(od_hat.T)\n\n    _, eigvecs = np.linalg.eigh(cov)\n\n    t_hat = od_hat.dot(eigvecs[:, 1:3])\n\n    phi = np.arctan2(t_hat[:, 1], t_hat[:, 0])\n\n    min_phi = np.percentile(phi, alpha)\n    max_phi = np.percentile(phi, 100 - alpha)\n\n    direction_min = np.array([np.cos(min_phi), np.sin(min_phi)], dtype=np.float32)\n    stain1 = eigvecs[:, 1:3].dot(direction_min).reshape(-1)\n    stain1 /= np.linalg.norm(stain1)\n\n    direction_max = np.array([np.cos(max_phi), np.sin(max_phi)], dtype=np.float32)\n    stain2 = eigvecs[:, 1:3].dot(direction_max).reshape(-1)\n    stain2 /= np.linalg.norm(stain2)\n\n    cos_angle11 = np.dot(stain1, default_stain_vectors[0])\n    cos_angle12 = np.dot(stain1, default_stain_vectors[1])\n    cos_angle21 = np.dot(stain2, default_stain_vectors[0])\n    cos_angle22 = np.dot(stain2, default_stain_vectors[1])\n\n    if max(cos_angle12, cos_angle21) &gt; max(cos_angle11, cos_angle22):\n        stain1, stain2 = stain2, stain1\n\n    return np.array([stain1, stain2, make_residual_stain(stain1, stain2)])\n</code></pre>"},{"location":"reference/augmentations/estimate_stain_vectors/#ratiopath.augmentations.estimate_stain_vectors.make_residual_stain","title":"<code>make_residual_stain(stain1, stain2)</code>","text":"<p>Create a residual stain vector from two stain vectors.</p> <p>Parameters:</p> Name Type Description Default <code>stain1</code> <code>ndarray</code> <p>A numpy array representing the first stain vector.</p> required <code>stain2</code> <code>ndarray</code> <p>A numpy array representing the second stain vector.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array representing the residual stain vector.</p> Source code in <code>ratiopath/augmentations/estimate_stain_vectors.py</code> <pre><code>def make_residual_stain(stain1: np.ndarray, stain2: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Create a residual stain vector from two stain vectors.\n\n    Parameters:\n        stain1: A numpy array representing the first stain vector.\n        stain2: A numpy array representing the second stain vector.\n\n    Returns:\n        A numpy array representing the residual stain vector.\n    \"\"\"\n    res = np.linalg.cross(stain1, stain2)\n    return res / np.linalg.norm(res)\n</code></pre>"},{"location":"reference/augmentations/stain_augmentor/","title":"ratiopath.augmentations.StainAugmentor","text":"<p>               Bases: <code>ImageOnlyTransform</code></p> <p>Applies stain augmentation to histopathological images.</p> Reference <p>Tellez, D., Balkenhol, M., Karssemeijer, N., Litjens, G., van der Laak, J., &amp; Ciompi, F. (2018, March). H&amp;E stain augmentation improves generalization of convolutional networks for histopathological mitosis detection. In Medical Imaging 2018: Digital Pathology (Vol. 10581, pp. 264-270). SPIE. https://geertlitjens.nl/publication/tell-18-a/tell-18-a.pdf</p> Source code in <code>ratiopath/augmentations/stain_augmentor.py</code> <pre><code>class StainAugmentor(ImageOnlyTransform):\n    \"\"\"Applies stain augmentation to histopathological images.\n\n    Reference:\n        Tellez, D., Balkenhol, M., Karssemeijer, N., Litjens, G.,\n        van der Laak, J., &amp; Ciompi, F. (2018, March). H&amp;E stain augmentation improves\n        generalization of convolutional networks for histopathological mitosis detection.\n        In Medical Imaging 2018: Digital Pathology (Vol. 10581, pp. 264-270). SPIE.\n        https://geertlitjens.nl/publication/tell-18-a/tell-18-a.pdf\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_matrix: Callable[[np.ndarray], np.ndarray] | np.ndarray,\n        alpha: float = 0.02,\n        beta: float = 0.02,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initializes StainAugmentor.\n\n        Args:\n            conv_matrix (Callable[[np.ndarray], np.ndarray] | np.ndarray): Stain matrix for stain separation.\n                Can be a fixed matrix or a callable that returns a matrix from an image.\n            alpha (float): Multiplicative factor range for stain augmentation.\n            beta (float): Additive factor range for stain augmentation.\n            **kwargs (Any): Keyword arguments for ImageOnlyTransform.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.conv_matrix = conv_matrix\n        self.alpha = alpha\n        self.beta = beta\n\n        if isinstance(self.conv_matrix, np.ndarray):\n            self.inv_conv_matrix = np.linalg.inv(self.conv_matrix)\n\n    def apply(\n        self,\n        img: np.ndarray,\n        conv_matrix: np.ndarray,\n        inv_conv_matrix: np.ndarray,\n        alphas: list[float],\n        betas: list[float],\n        **params: dict[str, Any],\n    ) -&gt; np.ndarray:\n        stains = separate_stains(img, inv_conv_matrix)\n\n        for i in range(stains.shape[-1]):\n            stains[..., i] *= alphas[i]\n            stains[..., i] += betas[i]\n\n        return np.astype(combine_stains(stains, conv_matrix) * 255, np.uint8)\n\n    def get_params_dependent_on_data(\n        self, params: dict[str, Any], data: dict[str, Any]\n    ) -&gt; dict[str, Any]:\n        conv_matrix = (\n            self.conv_matrix(data[\"image\"])\n            if callable(self.conv_matrix)\n            else self.conv_matrix\n        )\n        inv_conv_matrix = (\n            self.inv_conv_matrix\n            if hasattr(self, \"inv_conv_matrix\")\n            else np.linalg.inv(conv_matrix)\n        )\n\n        return {\n            \"conv_matrix\": conv_matrix,\n            \"inv_conv_matrix\": inv_conv_matrix,\n            \"alphas\": [\n                self.py_random.uniform(1 - self.alpha, 1 + self.alpha)\n                for _ in range(conv_matrix.shape[-1])\n            ],\n            \"betas\": [\n                self.py_random.uniform(-self.beta, self.beta)\n                for _ in range(conv_matrix.shape[-1])\n            ],\n        }\n</code></pre>"},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.alpha","title":"<code>alpha = alpha</code>  <code>instance-attribute</code>","text":""},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.beta","title":"<code>beta = beta</code>  <code>instance-attribute</code>","text":""},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.conv_matrix","title":"<code>conv_matrix = conv_matrix</code>  <code>instance-attribute</code>","text":""},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.inv_conv_matrix","title":"<code>inv_conv_matrix = np.linalg.inv(self.conv_matrix)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.__init__","title":"<code>__init__(conv_matrix, alpha=0.02, beta=0.02, **kwargs)</code>","text":"<p>Initializes StainAugmentor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_matrix</code> <code>Callable[[ndarray], ndarray] | ndarray</code> <p>Stain matrix for stain separation. Can be a fixed matrix or a callable that returns a matrix from an image.</p> required <code>alpha</code> <code>float</code> <p>Multiplicative factor range for stain augmentation.</p> <code>0.02</code> <code>beta</code> <code>float</code> <p>Additive factor range for stain augmentation.</p> <code>0.02</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments for ImageOnlyTransform.</p> <code>{}</code> Source code in <code>ratiopath/augmentations/stain_augmentor.py</code> <pre><code>def __init__(\n    self,\n    conv_matrix: Callable[[np.ndarray], np.ndarray] | np.ndarray,\n    alpha: float = 0.02,\n    beta: float = 0.02,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initializes StainAugmentor.\n\n    Args:\n        conv_matrix (Callable[[np.ndarray], np.ndarray] | np.ndarray): Stain matrix for stain separation.\n            Can be a fixed matrix or a callable that returns a matrix from an image.\n        alpha (float): Multiplicative factor range for stain augmentation.\n        beta (float): Additive factor range for stain augmentation.\n        **kwargs (Any): Keyword arguments for ImageOnlyTransform.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.conv_matrix = conv_matrix\n    self.alpha = alpha\n    self.beta = beta\n\n    if isinstance(self.conv_matrix, np.ndarray):\n        self.inv_conv_matrix = np.linalg.inv(self.conv_matrix)\n</code></pre>"},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.apply","title":"<code>apply(img, conv_matrix, inv_conv_matrix, alphas, betas, **params)</code>","text":"Source code in <code>ratiopath/augmentations/stain_augmentor.py</code> <pre><code>def apply(\n    self,\n    img: np.ndarray,\n    conv_matrix: np.ndarray,\n    inv_conv_matrix: np.ndarray,\n    alphas: list[float],\n    betas: list[float],\n    **params: dict[str, Any],\n) -&gt; np.ndarray:\n    stains = separate_stains(img, inv_conv_matrix)\n\n    for i in range(stains.shape[-1]):\n        stains[..., i] *= alphas[i]\n        stains[..., i] += betas[i]\n\n    return np.astype(combine_stains(stains, conv_matrix) * 255, np.uint8)\n</code></pre>"},{"location":"reference/augmentations/stain_augmentor/#ratiopath.augmentations.StainAugmentor.get_params_dependent_on_data","title":"<code>get_params_dependent_on_data(params, data)</code>","text":"Source code in <code>ratiopath/augmentations/stain_augmentor.py</code> <pre><code>def get_params_dependent_on_data(\n    self, params: dict[str, Any], data: dict[str, Any]\n) -&gt; dict[str, Any]:\n    conv_matrix = (\n        self.conv_matrix(data[\"image\"])\n        if callable(self.conv_matrix)\n        else self.conv_matrix\n    )\n    inv_conv_matrix = (\n        self.inv_conv_matrix\n        if hasattr(self, \"inv_conv_matrix\")\n        else np.linalg.inv(conv_matrix)\n    )\n\n    return {\n        \"conv_matrix\": conv_matrix,\n        \"inv_conv_matrix\": inv_conv_matrix,\n        \"alphas\": [\n            self.py_random.uniform(1 - self.alpha, 1 + self.alpha)\n            for _ in range(conv_matrix.shape[-1])\n        ],\n        \"betas\": [\n            self.py_random.uniform(-self.beta, self.beta)\n            for _ in range(conv_matrix.shape[-1])\n        ],\n    }\n</code></pre>"},{"location":"reference/parsers/asap/","title":"ratiopath.parsers.ASAPParser","text":"<p>Parser for ASAP format annotation files.</p> <p>ASAP (Automated Slide Analysis Platform) uses XML format for storing annotations. This parser supports both polygon and point annotations.</p> Source code in <code>ratiopath/parsers/asap_parser.py</code> <pre><code>class ASAPParser:\n    \"\"\"Parser for ASAP format annotation files.\n\n    ASAP (Automated Slide Analysis Platform) uses XML format for storing annotations.\n    This parser supports both polygon and point annotations.\n    \"\"\"\n\n    def __init__(self, file_path: Path | str | TextIO):\n        self.tree = ET.parse(file_path)\n        self.root = self.tree.getroot()\n\n    def _get_filtered_annotations(\n        self, name: str, part_of_group: str\n    ) -&gt; Iterable[ET.Element]:\n        \"\"\"Get annotations that match the provided regex filters.\n\n        Args:\n            name: Regex pattern to match annotation names.\n            part_of_group: Regex pattern to match annotation groups.\n\n        Yields:\n            XML annotation elements that match the filters.\n        \"\"\"\n        name_regex = re.compile(name)\n        part_of_group_regex = re.compile(part_of_group)\n\n        for annotation in self.root.findall(\".//Annotation\"):\n            if name_regex.match(\n                annotation.attrib[\"Name\"]\n            ) and part_of_group_regex.match(annotation.attrib[\"PartOfGroup\"]):\n                yield annotation\n\n    def _extract_coordinates(self, annotation: ET.Element) -&gt; list[Point]:\n        \"\"\"Extract coordinates from an annotation element.\n\n        Args:\n            annotation: XML annotation element.\n\n        Returns:\n            List of (x, y) coordinate tuples.\n        \"\"\"\n        return [\n            Point(float(coordinate.attrib[\"X\"]), float(coordinate.attrib[\"Y\"]))\n            for coordinate in annotation.findall(\".//Coordinate\")\n        ]\n\n    def get_polygons(\n        self, name: str = \".*\", part_of_group: str = \".*\"\n    ) -&gt; Iterable[Polygon]:\n        \"\"\"Parse polygon annotations from ASAP XML file.\n\n        Args:\n            name: Regex pattern to match annotation names.\n            part_of_group: Regex pattern to match annotation groups.\n\n        Returns:\n            An iterable of shapely Polygon objects.\n        \"\"\"\n        for annotation in self._get_filtered_annotations(name, part_of_group):\n            if annotation.attrib[\"Type\"] in [\"Polygon\", \"Spline\"]:\n                yield Polygon(self._extract_coordinates(annotation))\n\n    def get_points(\n        self, name: str = \".*\", part_of_group: str = \".*\"\n    ) -&gt; Iterable[Point]:\n        \"\"\"Parse point annotations from ASAP XML file.\n\n        Args:\n            name: Regex pattern to match annotation names.\n            part_of_group: Regex pattern to match annotation groups.\n\n        Returns:\n            An iterable of shapely Point objects.\n        \"\"\"\n        for annotation in self._get_filtered_annotations(name, part_of_group):\n            if annotation.attrib[\"Type\"] in [\"Point\", \"Dot\"]:\n                yield from self._extract_coordinates(annotation)\n</code></pre>"},{"location":"reference/parsers/asap/#ratiopath.parsers.ASAPParser.root","title":"<code>root = self.tree.getroot()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/parsers/asap/#ratiopath.parsers.ASAPParser.tree","title":"<code>tree = ET.parse(file_path)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/parsers/asap/#ratiopath.parsers.ASAPParser.__init__","title":"<code>__init__(file_path)</code>","text":"Source code in <code>ratiopath/parsers/asap_parser.py</code> <pre><code>def __init__(self, file_path: Path | str | TextIO):\n    self.tree = ET.parse(file_path)\n    self.root = self.tree.getroot()\n</code></pre>"},{"location":"reference/parsers/asap/#ratiopath.parsers.ASAPParser.get_points","title":"<code>get_points(name='.*', part_of_group='.*')</code>","text":"<p>Parse point annotations from ASAP XML file.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Regex pattern to match annotation names.</p> <code>'.*'</code> <code>part_of_group</code> <code>str</code> <p>Regex pattern to match annotation groups.</p> <code>'.*'</code> <p>Returns:</p> Type Description <code>Iterable[Point]</code> <p>An iterable of shapely Point objects.</p> Source code in <code>ratiopath/parsers/asap_parser.py</code> <pre><code>def get_points(\n    self, name: str = \".*\", part_of_group: str = \".*\"\n) -&gt; Iterable[Point]:\n    \"\"\"Parse point annotations from ASAP XML file.\n\n    Args:\n        name: Regex pattern to match annotation names.\n        part_of_group: Regex pattern to match annotation groups.\n\n    Returns:\n        An iterable of shapely Point objects.\n    \"\"\"\n    for annotation in self._get_filtered_annotations(name, part_of_group):\n        if annotation.attrib[\"Type\"] in [\"Point\", \"Dot\"]:\n            yield from self._extract_coordinates(annotation)\n</code></pre>"},{"location":"reference/parsers/asap/#ratiopath.parsers.ASAPParser.get_polygons","title":"<code>get_polygons(name='.*', part_of_group='.*')</code>","text":"<p>Parse polygon annotations from ASAP XML file.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Regex pattern to match annotation names.</p> <code>'.*'</code> <code>part_of_group</code> <code>str</code> <p>Regex pattern to match annotation groups.</p> <code>'.*'</code> <p>Returns:</p> Type Description <code>Iterable[Polygon]</code> <p>An iterable of shapely Polygon objects.</p> Source code in <code>ratiopath/parsers/asap_parser.py</code> <pre><code>def get_polygons(\n    self, name: str = \".*\", part_of_group: str = \".*\"\n) -&gt; Iterable[Polygon]:\n    \"\"\"Parse polygon annotations from ASAP XML file.\n\n    Args:\n        name: Regex pattern to match annotation names.\n        part_of_group: Regex pattern to match annotation groups.\n\n    Returns:\n        An iterable of shapely Polygon objects.\n    \"\"\"\n    for annotation in self._get_filtered_annotations(name, part_of_group):\n        if annotation.attrib[\"Type\"] in [\"Polygon\", \"Spline\"]:\n            yield Polygon(self._extract_coordinates(annotation))\n</code></pre>"},{"location":"reference/parsers/geojson/","title":"ratiopath.parsers.GeoJSONParser","text":"<p>Parser for GeoJSON format annotation files.</p> <p>GeoJSON is a format for encoding geographic data structures using JSON. This parser supports both polygon and point geometries.</p> Source code in <code>ratiopath/parsers/geojson_parser.py</code> <pre><code>class GeoJSONParser:\n    \"\"\"Parser for GeoJSON format annotation files.\n\n    GeoJSON is a format for encoding geographic data structures using JSON.\n    This parser supports both polygon and point geometries.\n    \"\"\"\n\n    def __init__(self, file_path: Path | str | TextIO) -&gt; None:\n        self.gdf = gpd.read_file(file_path)\n\n        if not self.gdf.empty:\n            # Explode Multi-part geometries to simplify geometry handling\n            self.gdf = self.gdf.explode(index_parts=True)\n\n    def get_filtered_geodataframe(\n        self, separator: str = \"_\", **kwargs: str\n    ) -&gt; GeoDataFrame:\n        \"\"\"Filter the GeoDataFrame based on property values.\n\n        Args:\n            separator: The string used to separate keys in the filtering.\n            **kwargs: Keyword arguments for filtering. Keys are column names\n                (e.g., 'classification.name') and values are regex patterns to match\n                against.\n\n        Returns:\n            A filtered GeoDataFrame.\n        \"\"\"\n        filtered_gdf = self.gdf\n        for key, pattern in kwargs.items():\n            subkeys = key.split(separator)\n            if not subkeys or subkeys[0] not in filtered_gdf.columns:\n                # If the first part of the key doesn't exist, return an empty frame\n                return self.gdf.iloc[0:0]\n\n            series = filtered_gdf[subkeys[0]].astype(str)\n            if len(subkeys) &gt; 1:\n                mask = series.apply(is_json_dict)\n                series = series[mask].apply(lambda x: json.loads(x))\n                filtered_gdf = filtered_gdf[mask]\n\n            for subkey in subkeys[1:]:\n                mask = series.apply(\n                    lambda x, subkey=subkey: isinstance(x, dict) and subkey in x\n                )\n                series = series[mask].apply(lambda x, subkey=subkey: x[subkey])\n                filtered_gdf = filtered_gdf[mask]\n\n            series = series.astype(str)\n            mask = series.str.match(pattern, na=False)\n            filtered_gdf = filtered_gdf[mask]\n\n        return filtered_gdf\n\n    def get_polygons(self, **kwargs: str) -&gt; Iterable[Polygon]:\n        \"\"\"Get polygons from the GeoDataFrame.\n\n        Args:\n            **kwargs: Keyword arguments for filtering properties.\n\n        Yields:\n            Shapely Polygon objects.\n        \"\"\"\n        filtered_gdf = self.get_filtered_geodataframe(**kwargs)\n        for geom in filtered_gdf.geometry:\n            if isinstance(geom, Polygon):\n                yield geom\n\n    def get_points(self, **kwargs: str) -&gt; Iterable[Point]:\n        \"\"\"Get points from the GeoDataFrame.\n\n        Args:\n            **kwargs: Keyword arguments for filtering properties.\n\n        Yields:\n            Shapely Point objects.\n        \"\"\"\n        filtered_gdf = self.get_filtered_geodataframe(**kwargs)\n        for geom in filtered_gdf.geometry:\n            if isinstance(geom, Point):\n                yield geom\n</code></pre>"},{"location":"reference/parsers/geojson/#ratiopath.parsers.GeoJSONParser.gdf","title":"<code>gdf = gpd.read_file(file_path)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/parsers/geojson/#ratiopath.parsers.GeoJSONParser.__init__","title":"<code>__init__(file_path)</code>","text":"Source code in <code>ratiopath/parsers/geojson_parser.py</code> <pre><code>def __init__(self, file_path: Path | str | TextIO) -&gt; None:\n    self.gdf = gpd.read_file(file_path)\n\n    if not self.gdf.empty:\n        # Explode Multi-part geometries to simplify geometry handling\n        self.gdf = self.gdf.explode(index_parts=True)\n</code></pre>"},{"location":"reference/parsers/geojson/#ratiopath.parsers.GeoJSONParser.get_filtered_geodataframe","title":"<code>get_filtered_geodataframe(separator='_', **kwargs)</code>","text":"<p>Filter the GeoDataFrame based on property values.</p> <p>Parameters:</p> Name Type Description Default <code>separator</code> <code>str</code> <p>The string used to separate keys in the filtering.</p> <code>'_'</code> <code>**kwargs</code> <code>str</code> <p>Keyword arguments for filtering. Keys are column names (e.g., 'classification.name') and values are regex patterns to match against.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A filtered GeoDataFrame.</p> Source code in <code>ratiopath/parsers/geojson_parser.py</code> <pre><code>def get_filtered_geodataframe(\n    self, separator: str = \"_\", **kwargs: str\n) -&gt; GeoDataFrame:\n    \"\"\"Filter the GeoDataFrame based on property values.\n\n    Args:\n        separator: The string used to separate keys in the filtering.\n        **kwargs: Keyword arguments for filtering. Keys are column names\n            (e.g., 'classification.name') and values are regex patterns to match\n            against.\n\n    Returns:\n        A filtered GeoDataFrame.\n    \"\"\"\n    filtered_gdf = self.gdf\n    for key, pattern in kwargs.items():\n        subkeys = key.split(separator)\n        if not subkeys or subkeys[0] not in filtered_gdf.columns:\n            # If the first part of the key doesn't exist, return an empty frame\n            return self.gdf.iloc[0:0]\n\n        series = filtered_gdf[subkeys[0]].astype(str)\n        if len(subkeys) &gt; 1:\n            mask = series.apply(is_json_dict)\n            series = series[mask].apply(lambda x: json.loads(x))\n            filtered_gdf = filtered_gdf[mask]\n\n        for subkey in subkeys[1:]:\n            mask = series.apply(\n                lambda x, subkey=subkey: isinstance(x, dict) and subkey in x\n            )\n            series = series[mask].apply(lambda x, subkey=subkey: x[subkey])\n            filtered_gdf = filtered_gdf[mask]\n\n        series = series.astype(str)\n        mask = series.str.match(pattern, na=False)\n        filtered_gdf = filtered_gdf[mask]\n\n    return filtered_gdf\n</code></pre>"},{"location":"reference/parsers/geojson/#ratiopath.parsers.GeoJSONParser.get_points","title":"<code>get_points(**kwargs)</code>","text":"<p>Get points from the GeoDataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>str</code> <p>Keyword arguments for filtering properties.</p> <code>{}</code> <p>Yields:</p> Type Description <code>Iterable[Point]</code> <p>Shapely Point objects.</p> Source code in <code>ratiopath/parsers/geojson_parser.py</code> <pre><code>def get_points(self, **kwargs: str) -&gt; Iterable[Point]:\n    \"\"\"Get points from the GeoDataFrame.\n\n    Args:\n        **kwargs: Keyword arguments for filtering properties.\n\n    Yields:\n        Shapely Point objects.\n    \"\"\"\n    filtered_gdf = self.get_filtered_geodataframe(**kwargs)\n    for geom in filtered_gdf.geometry:\n        if isinstance(geom, Point):\n            yield geom\n</code></pre>"},{"location":"reference/parsers/geojson/#ratiopath.parsers.GeoJSONParser.get_polygons","title":"<code>get_polygons(**kwargs)</code>","text":"<p>Get polygons from the GeoDataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>str</code> <p>Keyword arguments for filtering properties.</p> <code>{}</code> <p>Yields:</p> Type Description <code>Iterable[Polygon]</code> <p>Shapely Polygon objects.</p> Source code in <code>ratiopath/parsers/geojson_parser.py</code> <pre><code>def get_polygons(self, **kwargs: str) -&gt; Iterable[Polygon]:\n    \"\"\"Get polygons from the GeoDataFrame.\n\n    Args:\n        **kwargs: Keyword arguments for filtering properties.\n\n    Yields:\n        Shapely Polygon objects.\n    \"\"\"\n    filtered_gdf = self.get_filtered_geodataframe(**kwargs)\n    for geom in filtered_gdf.geometry:\n        if isinstance(geom, Polygon):\n            yield geom\n</code></pre>"},{"location":"reference/ray/read_slides/","title":"ratiopath.ray.read_slides","text":""},{"location":"reference/ray/read_slides/#ratiopath.ray.read_slides.FILE_EXTENSIONS","title":"<code>FILE_EXTENSIONS = ['svs', 'tif', 'dcm', 'ndpi', 'vms', 'vmu', 'scn', 'mrxs', 'tiff', 'svslide', 'bif', 'czi', 'ome.tiff', 'ome.tif']</code>  <code>module-attribute</code>","text":""},{"location":"reference/ray/read_slides/#ratiopath.ray.read_slides.read_slides","title":"<code>read_slides(paths, *, tile_extent, stride, mpp=None, level=None, filesystem=None, ray_remote_args=None, meta_provider=None, partition_filter=None, partitioning=None, shuffle=None, ignore_missing_paths=False, file_extensions=FILE_EXTENSIONS, concurrency=None, override_num_blocks=None)</code>","text":"<p>Creates a :class:<code>~ray.data.Dataset</code> from whole slide image files.</p> <p>This function reads metadata from whole slide image (WSI) files and creates a Ray Dataset where each row corresponds to a single slide. The dataset contains metadata required for subsequent tiled processing, such as slide dimensions, resolution (MPP), and tiling parameters.</p> <p>It automatically selects the best slide level based on the specified <code>mpp</code> (microns per pixel) or uses the given <code>level</code>.</p> <p>Examples:</p> <p>Read a single slide and create a metadata dataset.</p> <pre><code>&gt;&gt;&gt; import ray\n&gt;&gt;&gt; from ratiopath.ray import read_slide\n&gt;&gt;&gt; ds = read_slide(\n...     \"path/to/slide.svs\",\n...     tile_extent=256,\n...     stride=256,\n...     mpp=0.5,\n... )\n&gt;&gt;&gt; ds.schema()\nColumn         Type\n------         ----\npath           string\nextent_x       int64\nextent_y       int64\ntile_extent_x  int64\ntile_extent_y  int64\nstride_x       int64\nstride_y       int64\nmpp_x          double\nmpp_y          double\nlevel          int64\ndownsample     double\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>str | list[str]</code> <p>A single file path or a list of file paths to whole slide images.</p> required <code>tile_extent</code> <code>int | tuple[int, int]</code> <p>The size of the tiles to be generated, as <code>(width, height)</code>. If a single integer is provided, it's used for both dimensions.</p> required <code>stride</code> <code>int | tuple[int, int]</code> <p>The step size between consecutive tiles, as <code>(x_stride, y_stride)</code>. If a single integer is provided, it's used for both dimensions.</p> required <code>mpp</code> <code>float | None</code> <p>The desired microns per pixel. The datasource will select the slide level with the closest MPP. Exactly one of <code>mpp</code> or <code>level</code> must be provided.</p> <code>None</code> <code>level</code> <code>int | None</code> <p>The desired slide level to use. Exactly one of <code>mpp</code> or <code>level</code> must be provided.</p> <code>None</code> <code>filesystem</code> <code>FileSystem | None</code> <p>The PyArrow filesystem implementation to read from. If not provided, it will be inferred from the file paths.</p> <code>None</code> <code>ray_remote_args</code> <code>dict[str, Any] | None</code> <p>kwargs passed to :func:<code>ray.remote</code> in the read tasks.</p> <code>None</code> <code>meta_provider</code> <code>BaseFileMetadataProvider | None</code> <p>Custom metadata providers may be able to resolve file metadata more quickly and/or accurately. In most cases you do not need to set this parameter.</p> <code>None</code> <code>partition_filter</code> <code>PathPartitionFilter | None</code> <p>A filter to read only selected partitions of a dataset.</p> <code>None</code> <code>partitioning</code> <code>Partitioning | None</code> <p>A :class:<code>~ray.data.datasource.partitioning.Partitioning</code> object that describes how paths are organized.</p> <code>None</code> <code>shuffle</code> <code>Literal['files'] | FileShuffleConfig | None</code> <p>If set to \"files\", randomly shuffles the input file order.</p> <code>None</code> <code>ignore_missing_paths</code> <code>bool</code> <p>If <code>True</code>, ignores any file paths that don't exist.</p> <code>False</code> <code>file_extensions</code> <code>list[str] | None</code> <p>A list of file extensions to filter files by. If <code>None</code>, it uses the default list of supported slide formats.</p> <code>FILE_EXTENSIONS</code> <code>concurrency</code> <code>int | None</code> <p>The maximum number of Ray tasks to run concurrently.</p> <code>None</code> <code>override_num_blocks</code> <code>int | None</code> <p>Override the number of output blocks from all read tasks.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>A</code> <code>Dataset</code> <p>class:<code>~ray.data.Dataset</code> where each row contains the metadata for one</p> <code>Dataset</code> <p>slide, ready for tiling operations.</p> Source code in <code>ratiopath/ray/read_slides.py</code> <pre><code>def read_slides(\n    paths: str | list[str],\n    *,\n    tile_extent: int | tuple[int, int],\n    stride: int | tuple[int, int],\n    mpp: float | None = None,\n    level: int | None = None,\n    filesystem: pyarrow.fs.FileSystem | None = None,\n    ray_remote_args: dict[str, Any] | None = None,\n    meta_provider: BaseFileMetadataProvider | None = None,\n    partition_filter: PathPartitionFilter | None = None,\n    partitioning: Partitioning | None = None,\n    shuffle: Literal[\"files\"] | FileShuffleConfig | None = None,\n    ignore_missing_paths: bool = False,\n    file_extensions: list[str] | None = FILE_EXTENSIONS,\n    concurrency: int | None = None,\n    override_num_blocks: int | None = None,\n) -&gt; Dataset:\n    \"\"\"Creates a :class:`~ray.data.Dataset` from whole slide image files.\n\n    This function reads metadata from whole slide image (WSI) files and creates a\n    Ray Dataset where each row corresponds to a single slide. The dataset contains\n    metadata required for subsequent tiled processing, such as slide dimensions,\n    resolution (MPP), and tiling parameters.\n\n    It automatically selects the best slide level based on the specified `mpp`\n    (microns per pixel) or uses the given `level`.\n\n    Examples:\n        Read a single slide and create a metadata dataset.\n\n        &gt;&gt;&gt; import ray\n        &gt;&gt;&gt; from ratiopath.ray import read_slide\n        &gt;&gt;&gt; ds = read_slide(  # doctest: +SKIP\n        ...     \"path/to/slide.svs\",\n        ...     tile_extent=256,\n        ...     stride=256,\n        ...     mpp=0.5,\n        ... )\n        &gt;&gt;&gt; ds.schema()  # doctest: +SKIP\n        Column         Type\n        ------         ----\n        path           string\n        extent_x       int64\n        extent_y       int64\n        tile_extent_x  int64\n        tile_extent_y  int64\n        stride_x       int64\n        stride_y       int64\n        mpp_x          double\n        mpp_y          double\n        level          int64\n        downsample     double\n\n    Args:\n        paths: A single file path or a list of file paths to whole slide images.\n        tile_extent: The size of the tiles to be generated, as `(width, height)`.\n            If a single integer is provided, it's used for both dimensions.\n        stride: The step size between consecutive tiles, as `(x_stride, y_stride)`.\n            If a single integer is provided, it's used for both dimensions.\n        mpp: The desired microns per pixel. The datasource will select the slide\n            level with the closest MPP. Exactly one of `mpp` or `level` must be\n            provided.\n        level: The desired slide level to use. Exactly one of `mpp` or `level`\n            must be provided.\n        filesystem: The PyArrow filesystem implementation to read from. If not\n            provided, it will be inferred from the file paths.\n        ray_remote_args: kwargs passed to :func:`ray.remote` in the read tasks.\n        meta_provider: Custom metadata providers may be able to resolve file metadata\n            more quickly and/or accurately. In most cases you do not need to set this\n            parameter.\n        partition_filter: A filter to read only selected partitions of a dataset.\n        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object\n            that describes how paths are organized.\n        shuffle: If set to \"files\", randomly shuffles the input file order.\n        ignore_missing_paths: If `True`, ignores any file paths that don't exist.\n        file_extensions: A list of file extensions to filter files by. If `None`,\n            it uses the default list of supported slide formats.\n        concurrency: The maximum number of Ray tasks to run concurrently.\n        override_num_blocks: Override the number of output blocks from all read tasks.\n\n    Returns:\n        A :class:`~ray.data.Dataset` where each row contains the metadata for one\n        slide, ready for tiling operations.\n    \"\"\"\n    _validate_shuffle_arg(shuffle)\n\n    if meta_provider is None:\n        meta_provider = SlideFileMetadataProvider()\n\n    datasource = SlideMetaDatasource(\n        paths,\n        tile_extent=tile_extent,\n        stride=stride,\n        mpp=mpp,\n        level=level,\n        filesystem=filesystem,\n        partition_filter=partition_filter,\n        partitioning=partitioning,\n        ignore_missing_paths=ignore_missing_paths,\n        shuffle=shuffle,\n        file_extensions=file_extensions,\n    )\n    return ray.data.read_datasource(\n        datasource,\n        ray_remote_args=ray_remote_args,\n        concurrency=concurrency,\n        override_num_blocks=override_num_blocks,\n    )\n</code></pre>"},{"location":"reference/ray/vips_tiff_datasink/","title":"ratiopath.ray.datasource.VipsTiffDatasink","text":"<p>               Bases: <code>RowBasedFileDatasink</code></p> <p>A datasink for saving image data as TIFF files using libvips.</p> <p>This datasink uses pyvips to efficiently save image data with support for various TIFF formats, including BigTIFF.</p> Source code in <code>ratiopath/ray/datasource/vips_tiff_datasink.py</code> <pre><code>class VipsTiffDatasink(RowBasedFileDatasink):\n    \"\"\"A datasink for saving image data as TIFF files using libvips.\n\n    This datasink uses pyvips to efficiently save image data with support for\n    various TIFF formats, including BigTIFF.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str,\n        data_column: str,\n        options_column: str | None = None,\n        default_options: dict[str, Any] | None = None,\n        **file_datasink_kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize a VipsTIFFDatasink.\n\n        Args:\n            path: Output path for the TIFF files\n            data_column: Column name containing image data (numpy array)\n            options_column: Optional column name containing TIFF save options as dict\n            default_options: Default options for TIFF saving\n            **file_datasink_kwargs: Additional arguments for the file datasink\n        \"\"\"\n        super().__init__(path, file_format=\"tiff\", **file_datasink_kwargs)\n        self.data_column = data_column\n        self.options_column = options_column\n        self.default_options = default_options or {}\n\n    def write_row_to_file(self, row: dict[str, Any], file: pyarrow.NativeFile) -&gt; None:\n        from pyvips import Image\n\n        image = Image.new_from_array(row[self.data_column])\n        options = self.default_options.copy()\n        if self.options_column is not None:\n            options.update(row.get(self.options_column, {}))\n\n        buffer = image.tiffsave_buffer(**options)\n        file.write(buffer)\n</code></pre>"},{"location":"reference/ray/vips_tiff_datasink/#ratiopath.ray.datasource.VipsTiffDatasink.data_column","title":"<code>data_column = data_column</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ray/vips_tiff_datasink/#ratiopath.ray.datasource.VipsTiffDatasink.default_options","title":"<code>default_options = default_options or {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ray/vips_tiff_datasink/#ratiopath.ray.datasource.VipsTiffDatasink.options_column","title":"<code>options_column = options_column</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ray/vips_tiff_datasink/#ratiopath.ray.datasource.VipsTiffDatasink.__init__","title":"<code>__init__(path, data_column, options_column=None, default_options=None, **file_datasink_kwargs)</code>","text":"<p>Initialize a VipsTIFFDatasink.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output path for the TIFF files</p> required <code>data_column</code> <code>str</code> <p>Column name containing image data (numpy array)</p> required <code>options_column</code> <code>str | None</code> <p>Optional column name containing TIFF save options as dict</p> <code>None</code> <code>default_options</code> <code>dict[str, Any] | None</code> <p>Default options for TIFF saving</p> <code>None</code> <code>**file_datasink_kwargs</code> <code>Any</code> <p>Additional arguments for the file datasink</p> <code>{}</code> Source code in <code>ratiopath/ray/datasource/vips_tiff_datasink.py</code> <pre><code>def __init__(\n    self,\n    path: str,\n    data_column: str,\n    options_column: str | None = None,\n    default_options: dict[str, Any] | None = None,\n    **file_datasink_kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize a VipsTIFFDatasink.\n\n    Args:\n        path: Output path for the TIFF files\n        data_column: Column name containing image data (numpy array)\n        options_column: Optional column name containing TIFF save options as dict\n        default_options: Default options for TIFF saving\n        **file_datasink_kwargs: Additional arguments for the file datasink\n    \"\"\"\n    super().__init__(path, file_format=\"tiff\", **file_datasink_kwargs)\n    self.data_column = data_column\n    self.options_column = options_column\n    self.default_options = default_options or {}\n</code></pre>"},{"location":"reference/ray/vips_tiff_datasink/#ratiopath.ray.datasource.VipsTiffDatasink.write_row_to_file","title":"<code>write_row_to_file(row, file)</code>","text":"Source code in <code>ratiopath/ray/datasource/vips_tiff_datasink.py</code> <pre><code>def write_row_to_file(self, row: dict[str, Any], file: pyarrow.NativeFile) -&gt; None:\n    from pyvips import Image\n\n    image = Image.new_from_array(row[self.data_column])\n    options = self.default_options.copy()\n    if self.options_column is not None:\n        options.update(row.get(self.options_column, {}))\n\n    buffer = image.tiffsave_buffer(**options)\n    file.write(buffer)\n</code></pre>"},{"location":"reference/tiling/annotations/","title":"ratiopath.tiling.annotations","text":""},{"location":"reference/tiling/annotations/#ratiopath.tiling.annotations.annotations_intersection","title":"<code>annotations_intersection(tree, roi)</code>","text":"<p>Get the intersection of annotations with the region of interest (ROI).</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>STRtree</code> <p>The spatial index of annotation geometries.</p> required <code>roi</code> <code>BaseGeometry</code> <p>The region of interest geometry.</p> required <p>Returns:</p> Name Type Description <code>BaseGeometry</code> <code>BaseGeometry</code> <p>The intersection of annotations with the ROI.</p> Source code in <code>ratiopath/tiling/annotations.py</code> <pre><code>def annotations_intersection(tree: STRtree, roi: BaseGeometry) -&gt; BaseGeometry:\n    \"\"\"Get the intersection of annotations with the region of interest (ROI).\n\n    Args:\n        tree: The spatial index of annotation geometries.\n        roi: The region of interest geometry.\n\n    Returns:\n        BaseGeometry: The intersection of annotations with the ROI.\n    \"\"\"\n    intersection = Polygon()\n    for polygon_index in tree.query(roi, predicate=\"intersects\"):\n        intersection = intersection.union(\n            tree.geometries[int(polygon_index)].intersection(roi)\n        )\n    return intersection\n</code></pre>"},{"location":"reference/tiling/annotations/#ratiopath.tiling.annotations.shift_roi","title":"<code>shift_roi(roi, coordinate, downsample)</code>","text":"<p>Shift the region of interest (ROI) for a specific tile.</p> <p>Parameters:</p> Name Type Description Default <code>roi</code> <code>BaseGeometry</code> <p>The current region of interest geometry.</p> required <code>coordinate</code> <code>NDArray[int64]</code> <p>The coordinates of the tile to shift the ROI for.</p> required <code>downsample</code> <code>float</code> <p>The downsampling factor.</p> required <p>Returns:</p> Name Type Description <code>BaseGeometry</code> <code>BaseGeometry</code> <p>The shifted region of interest geometry.</p> Source code in <code>ratiopath/tiling/annotations.py</code> <pre><code>def shift_roi(\n    roi: BaseGeometry, coordinate: NDArray[np.int64], downsample: float\n) -&gt; BaseGeometry:\n    \"\"\"Shift the region of interest (ROI) for a specific tile.\n\n    Args:\n        roi: The current region of interest geometry.\n        coordinate: The coordinates of the tile to shift the ROI for.\n        downsample: The downsampling factor.\n\n    Returns:\n        BaseGeometry: The shifted region of interest geometry.\n    \"\"\"\n    return transform(roi, lambda r: r + coordinate * downsample)\n</code></pre>"},{"location":"reference/tiling/annotations/#ratiopath.tiling.annotations.tile_annotations","title":"<code>tile_annotations(annotations, roi, coordinates, downsample)</code>","text":"<p>Yield annotated tiles from the annotation tree.</p> <p>Annotations are assumed to be at level 0. Yielded geometries are transformed to the same level as the ROI and tiles.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Iterable[BaseGeometry]</code> <p>The list of annotation geometries.</p> required <code>roi</code> <code>BaseGeometry</code> <p>The region of interest geometry.</p> required <code>coordinates</code> <code>Iterable[NDArray[int64]]</code> <p>The iterable of coordinates of the tiles.</p> required <code>downsample</code> <code>float</code> <p>The downsampling factor.</p> required <p>Yields:</p> Name Type Description <code>BaseGeometry</code> <code>BaseGeometry</code> <p>The annotated tile geometry.</p> Source code in <code>ratiopath/tiling/annotations.py</code> <pre><code>def tile_annotations(\n    annotations: Iterable[BaseGeometry],\n    roi: BaseGeometry,\n    coordinates: Iterable[NDArray[np.int64]],\n    downsample: float,\n) -&gt; Iterator[BaseGeometry]:\n    \"\"\"Yield annotated tiles from the annotation tree.\n\n    Annotations are assumed to be at level 0. Yielded geometries are transformed to the\n    same level as the ROI and tiles.\n\n    Args:\n        annotations: The list of annotation geometries.\n        roi: The region of interest geometry.\n        coordinates: The iterable of coordinates of the tiles.\n        downsample: The downsampling factor.\n\n    Yields:\n        BaseGeometry: The annotated tile geometry.\n    \"\"\"\n    tree = STRtree(annotations)\n    # transform roi to level 0\n    roi = transform(roi, lambda geom: geom * downsample)\n\n    for coordinate in coordinates:\n        shifted_roi = shift_roi(roi, coordinate, downsample)\n        intersection = annotations_intersection(tree, shifted_roi)\n        yield transform(intersection, lambda geom: geom / downsample)\n</code></pre>"},{"location":"reference/tiling/overlays/","title":"ratiopath.tiling.overlays","text":""},{"location":"reference/tiling/overlays/#ratiopath.tiling.overlays.tile_overlay","title":"<code>tile_overlay(roi, overlay_path, tile_x, tile_y, mpp_x, mpp_y)</code>","text":"<p>Read overlay tiles for a batch of tiles.</p> <p>For each overlay path the corresponding whole-slide image is opened (OpenSlide or OME-TIFF). The overlay is accessed at the slide level closest to each tile's mpp and the tile coordinates/extents are scaled to that level before reading.</p> <p>The region of interest (ROI) geometry is treated in the same image space (resolution) as the underlying slide tiles. The region can be an arbitrary polygon. However, a bounding box of the region is used for reading overlay tiles and then masked to respect the region defined by provided overlay.</p> <p>Unfortunately, at the moment we cannot use masked arrays directly in Ray Dataset. So instead of a numpy masked array, we provide the data and the mask as 2 separate arrays. The implementation is handled via TensorArray.</p> <p>Parameters:</p> Name Type Description Default <code>roi</code> <code>BaseGeometry</code> <p>The region of interest geometry.</p> required <code>overlay_path</code> <code>StringArray</code> <p>A pyarrow array of whole-slide image paths for the overlays.</p> required <code>tile_x</code> <code>IntegerArray</code> <p>A pyarrow array of tile x-coordinates.</p> required <code>tile_y</code> <code>IntegerArray</code> <p>A pyarrow array of tile y-coordinates.</p> required <code>mpp_x</code> <code>FloatArray</code> <p>A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in X direction.</p> required <code>mpp_y</code> <code>FloatArray</code> <p>A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in Y direction.</p> required <p>Returns:</p> Type Description <code>Array</code> <p>A pyarrow array of masked numpy arrays containing the read overlay tiles. - The first element is the tile data. - The second element is the mask (True for pixels outside the ROI).</p> Source code in <code>ratiopath/tiling/overlays.py</code> <pre><code>@udf(return_dtype=DataType(np.ndarray))\ndef tile_overlay(\n    roi: BaseGeometry,\n    overlay_path: pa.StringArray,\n    tile_x: pa.IntegerArray,\n    tile_y: pa.IntegerArray,\n    mpp_x: pa.FloatArray,\n    mpp_y: pa.FloatArray,\n) -&gt; pa.Array:\n    \"\"\"Read overlay tiles for a batch of tiles.\n\n    For each overlay path the corresponding whole-slide image is opened (OpenSlide or OME-TIFF).\n    The overlay is accessed at the slide level closest to each tile's mpp and the tile\n    coordinates/extents are scaled to that level before reading.\n\n    The region of interest (ROI) geometry is treated in the same image space (resolution) as the underlying slide tiles.\n    The region can be an arbitrary polygon. However, a bounding box of the region is used for reading overlay tiles\n    and then masked to respect the region defined by provided overlay.\n\n    Unfortunately, at the moment we cannot use masked arrays directly in Ray Dataset. So instead of a numpy masked array,\n    we provide the data and the mask as 2 separate arrays. The implementation is handled via TensorArray.\n\n    Args:\n        roi: The region of interest geometry.\n        overlay_path: A pyarrow array of whole-slide image paths for the overlays.\n        tile_x: A pyarrow array of tile x-coordinates.\n        tile_y: A pyarrow array of tile y-coordinates.\n        mpp_x: A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in X direction.\n        mpp_y: A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in Y direction.\n\n    Returns:\n        A pyarrow array of masked numpy arrays containing the read overlay tiles.\n            - The first element is the tile data.\n            - The second element is the mask (True for pixels outside the ROI).\n    \"\"\"\n    overlays = _tile_overlay(roi, overlay_path, tile_x, tile_y, mpp_x, mpp_y)\n\n    return pa.array(TensorArray([[overlay.data, overlay.mask] for overlay in overlays]))\n</code></pre>"},{"location":"reference/tiling/overlays/#ratiopath.tiling.overlays.tile_overlay_overlap","title":"<code>tile_overlay_overlap(roi, overlay_path, tile_x, tile_y, mpp_x, mpp_y)</code>","text":"<p>Calculate the overlap of each overlay tile with the region of interest (ROI).</p> <p>For each overlay path the corresponding whole-slide image is opened (OpenSlide or OME-TIFF). The overlay is accessed at the slide level closest to each tile's mpp and the tile coordinates/extents are scaled to that level before reading.</p> <p>The region of interest (ROI) geometry is treated in the same image space (resolution) as the underlying slide tiles. The region can be an arbitrary polygon.</p> <p>The Pyarrow array that is used inside ray dataset stores data in array like dictionary. This results in all rows having same set of keys and missing keys are filled with Nones. Furthermore Pyarrow only support string keys in dictionaries. Therefore the keys in the resulting dictionary are string representations of the overlay values.</p> <p>Parameters:</p> Name Type Description Default <code>roi</code> <code>BaseGeometry</code> <p>The region of interest geometry.</p> required <code>overlay_path</code> <code>StringArray</code> <p>A pyarrow array of whole-slide image paths for the overlays.</p> required <code>tile_x</code> <code>IntegerArray</code> <p>A pyarrow array of tile x-coordinates.</p> required <code>tile_y</code> <code>IntegerArray</code> <p>A pyarrow array of tile y-coordinates.</p> required <code>mpp_x</code> <code>FloatArray</code> <p>A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in X direction.</p> required <code>mpp_y</code> <code>FloatArray</code> <p>A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in Y direction.</p> required <p>Returns:</p> Type Description <code>MapArray</code> <p>A pyarrow array of dictionaries mapping overlay values to their overlap fraction with the ROI.</p> Source code in <code>ratiopath/tiling/overlays.py</code> <pre><code>@udf(return_dtype=DataType(dict))\ndef tile_overlay_overlap(\n    roi: BaseGeometry,\n    overlay_path: pa.StringArray,\n    tile_x: pa.IntegerArray,\n    tile_y: pa.IntegerArray,\n    mpp_x: pa.FloatArray,\n    mpp_y: pa.FloatArray,\n) -&gt; pa.MapArray:\n    \"\"\"Calculate the overlap of each overlay tile with the region of interest (ROI).\n\n    For each overlay path the corresponding whole-slide image is opened (OpenSlide or OME-TIFF).\n    The overlay is accessed at the slide level closest to each tile's mpp and the tile\n    coordinates/extents are scaled to that level before reading.\n\n    The region of interest (ROI) geometry is treated in the same image space (resolution) as the underlying slide tiles.\n    The region can be an arbitrary polygon.\n\n    The Pyarrow array that is used inside ray dataset stores data in array like dictionary.\n    This results in all rows having same set of keys and missing keys are filled with Nones.\n    Furthermore Pyarrow only support string keys in dictionaries. Therefore the keys in the\n    resulting dictionary are string representations of the overlay values.\n\n    Args:\n        roi: The region of interest geometry.\n        overlay_path: A pyarrow array of whole-slide image paths for the overlays.\n        tile_x: A pyarrow array of tile x-coordinates.\n        tile_y: A pyarrow array of tile y-coordinates.\n        mpp_x: A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in X direction.\n        mpp_y: A pyarrow array of physical resolutions (\u00b5m/px) of the underlying slide in Y direction.\n\n    Returns:\n        A pyarrow array of dictionaries mapping overlay values to their overlap fraction with the ROI.\n    \"\"\"\n    # The overlay is a masked array where the mask is True for pixels outside the ROI.\n    overlay = _tile_overlay(roi, overlay_path, tile_x, tile_y, mpp_x, mpp_y)\n\n    def overlap_fraction(overlay: np.ma.MaskedArray) -&gt; dict[str, float]:\n        \"\"\"Calculate the overlap fraction of each unique value in the overlay.\"\"\"\n        return {\n            # Pyarrow requires string keys in dictionaries\n            str(value.item()): count.item() / overlay.count()\n            for value, count in zip(\n                *np.unique(overlay.compressed(), return_counts=True), strict=True\n            )\n        }\n\n    overlap_vectorized = np.vectorize(overlap_fraction, otypes=[object])\n\n    return pa.array(overlap_vectorized(overlay))\n</code></pre>"},{"location":"reference/tiling/read_slide_tile/","title":"ratiopath.tiling.read_slide_tiles","text":""},{"location":"reference/tiling/read_slide_tile/#ratiopath.tiling.read_slide_tiles.read_openslide_tiles","title":"<code>read_openslide_tiles(path, **kwargs)</code>","text":"<p>Read batch of tiles from a whole-slide image using OpenSlide.</p> Source code in <code>ratiopath/tiling/read_slide_tiles.py</code> <pre><code>def read_openslide_tiles(path: str, **kwargs: Unpack[ReadTilesArguments]) -&gt; np.ndarray:\n    \"\"\"Read batch of tiles from a whole-slide image using OpenSlide.\"\"\"\n    with OpenSlide(path) as slide:\n        return _read_openslide_tiles(slide, **kwargs)\n</code></pre>"},{"location":"reference/tiling/read_slide_tile/#ratiopath.tiling.read_slide_tiles.read_slide_tiles","title":"<code>read_slide_tiles(path, tile_x, tile_y, tile_extent_x, tile_extent_y, level)</code>","text":"<p>Reads a batch of tiles from a whole-slide image using either OpenSlide or tifffile.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>StringArray</code> <p>A pyarrow array of whole-slide image paths.</p> required <code>tile_x</code> <code>IntegerArray</code> <p>A pyarrow array of tile x-coordinates.</p> required <code>tile_y</code> <code>IntegerArray</code> <p>A pyarrow array of tile y-coordinates.</p> required <code>tile_extent_x</code> <code>IntegerArray</code> <p>A pyarrow array of tile extents in the x-dimension.</p> required <code>tile_extent_y</code> <code>IntegerArray</code> <p>A pyarrow array of tile extents in the y-dimension.</p> required <code>level</code> <code>IntegerArray</code> <p>A pyarrow array of slide levels to read the tiles from.</p> required <p>Returns:</p> Type Description <code>Array</code> <p>A pyarrow array of numpy arrays containing the read tiles.</p> Source code in <code>ratiopath/tiling/read_slide_tiles.py</code> <pre><code>@udf(return_dtype=DataType(np.ndarray))\ndef read_slide_tiles(\n    path: pa.StringArray,\n    tile_x: pa.IntegerArray,\n    tile_y: pa.IntegerArray,\n    tile_extent_x: pa.IntegerArray,\n    tile_extent_y: pa.IntegerArray,\n    level: pa.IntegerArray,\n) -&gt; pa.Array:\n    \"\"\"Reads a batch of tiles from a whole-slide image using either OpenSlide or tifffile.\n\n    Args:\n        path: A pyarrow array of whole-slide image paths.\n        tile_x: A pyarrow array of tile x-coordinates.\n        tile_y: A pyarrow array of tile y-coordinates.\n        tile_extent_x: A pyarrow array of tile extents in the x-dimension.\n        tile_extent_y: A pyarrow array of tile extents in the y-dimension.\n        level: A pyarrow array of slide levels to read the tiles from.\n\n    Returns:\n        A pyarrow array of numpy arrays containing the read tiles.\n    \"\"\"\n    import pyarrow.compute as pc\n\n    tiles = np.empty(len(tile_x), dtype=object)\n\n    for p, group in _pyarrow_group_indices(path).items():\n        assert isinstance(p, str)\n\n        kwargs = {\n            \"tile_x\": pc.take(tile_x, group),\n            \"tile_y\": pc.take(tile_y, group),\n            \"tile_extent_x\": pc.take(tile_extent_x, group),\n            \"tile_extent_y\": pc.take(tile_extent_y, group),\n            \"level\": pc.take(level, group),\n        }\n\n        # Check if it's an OME-TIFF file\n        if p.lower().endswith((\".ome.tiff\", \".ome.tif\")):\n            tiles[group] = list(read_tifffile_tiles(p, **kwargs))\n        else:\n            tiles[group] = list(read_openslide_tiles(p, **kwargs))\n\n    return pa.array(TensorArray(tiles))\n</code></pre>"},{"location":"reference/tiling/read_slide_tile/#ratiopath.tiling.read_slide_tiles.read_tifffile_tiles","title":"<code>read_tifffile_tiles(path, **kwargs)</code>","text":"<p>Read batch of tiles from an OME-TIFF file using tifffile.</p> Source code in <code>ratiopath/tiling/read_slide_tiles.py</code> <pre><code>def read_tifffile_tiles(path: str, **kwargs: Unpack[ReadTilesArguments]) -&gt; np.ndarray:\n    \"\"\"Read batch of tiles from an OME-TIFF file using tifffile.\"\"\"\n    with TiffFile(path) as slide:\n        return _read_tifffile_tiles(slide, **kwargs)\n</code></pre>"},{"location":"reference/tiling/tilers/","title":"ratiopath.tiling.tilers","text":""},{"location":"reference/tiling/tilers/#ratiopath.tiling.tilers.Dims","title":"<code>Dims = TypeVarTuple('Dims')</code>  <code>module-attribute</code>","text":""},{"location":"reference/tiling/tilers/#ratiopath.tiling.tilers.grid_tiles","title":"<code>grid_tiles(slide_extent, tile_extent, stride, last='keep')</code>","text":"<p>Generates tiles for the given slide based on its size, tile size, and stride.</p> <p>The function yields tile coordinates in row-major order, iterating first over the x-axis (e.g. (0,0,...), (1,0,...), (2,0,...)) before incrementing the y-axis (0,1,...), (1,1,...), etc.</p> <p>Parameters:</p> Name Type Description Default <code>slide_extent</code> <code>tuple[int, *Dims]</code> <p>The dimensions of the slide in pixels.</p> required <code>tile_extent</code> <code>tuple[int, *Dims]</code> <p>The dimensions of the tile in pixels.</p> required <code>stride</code> <code>tuple[int, *Dims]</code> <p>The stride between tiles in pixels.</p> required <code>last</code> <code>Literal['shift', 'drop', 'keep']</code> <p>The strategy to handle the last tile when it does not fit the stride. - \"shift\": Shift the last tile to the left and up to fit the stride. - \"drop\": Drop the last tile if it does not fit the stride. - \"keep\": Keep the last tile even if it does not fit the slide.</p> <code>'keep'</code> <p>Returns:</p> Type Description <code>Iterator[NDArray[int64]]</code> <p>An iterator of numpy arrays containing the tile coordinates.</p> Source code in <code>ratiopath/tiling/tilers.py</code> <pre><code>def grid_tiles(\n    slide_extent: tuple[int, *Dims],\n    tile_extent: tuple[int, *Dims],\n    stride: tuple[int, *Dims],\n    last: Literal[\"shift\", \"drop\", \"keep\"] = \"keep\",\n) -&gt; Iterator[NDArray[np.int64]]:\n    \"\"\"Generates tiles for the given slide based on its size, tile size, and stride.\n\n    The function yields tile coordinates in row-major order, iterating first over the\n    x-axis (e.g. (0,0,...), (1,0,...), (2,0,...)) before incrementing the y-axis\n    (0,1,...), (1,1,...), etc.\n\n    Args:\n        slide_extent: The dimensions of the slide in pixels.\n        tile_extent: The dimensions of the tile in pixels.\n        stride: The stride between tiles in pixels.\n        last: The strategy to handle the last tile when it does not fit the stride.\n            - \"shift\": Shift the last tile to the left and up to fit the stride.\n            - \"drop\": Drop the last tile if it does not fit the stride.\n            - \"keep\": Keep the last tile even if it does not fit the slide.\n\n    Returns:\n        An iterator of numpy arrays containing the tile coordinates.\n    \"\"\"\n    slide_extent_array = np.asarray(slide_extent)\n    tile_extent_array = np.asarray(tile_extent)\n    stride_array = np.asarray(stride)\n\n    if any(tile_extent_array &gt; slide_extent_array):\n        warnings.warn(\n            f\"TilingModule: tile size {tile_extent_array} is greater than slide dimensions {slide_extent_array}\",\n            UserWarning,\n            stacklevel=2,\n        )\n\n    dim_max = (slide_extent_array - tile_extent_array) / stride_array\n    dim_max = np.floor(dim_max) if last == \"drop\" else np.ceil(dim_max)\n    dim_max = dim_max.astype(int)\n\n    # Reverse the dimension max array to iterate over 'x' coordinates first\n    dim_max = dim_max[::-1]\n\n    # Generate tile coordinates\n    if last == \"drop\" or last == \"keep\":\n        for i in itertools.product(*map(range, dim_max + 1)):\n            yield np.array(i[::-1]) * stride_array\n\n    elif last == \"shift\":\n        for i in itertools.product(*map(range, dim_max + 1)):\n            base_coord = np.array(i[::-1]) * stride_array\n            yield np.minimum(base_coord, slide_extent_array - tile_extent_array)\n</code></pre>"},{"location":"reference/tiling/utils/","title":"ratiopath.tiling.utils","text":""},{"location":"reference/tiling/utils/#ratiopath.tiling.utils.row_hash","title":"<code>row_hash(row, column='id', algorithm=hashlib.sha256)</code>","text":"<p>Hashes a row (dictionary) using SHA256 and adds the hash as a new column.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, Any]</code> <p>The dictionary (row) to hash.</p> required <code>column</code> <code>str</code> <p>The name of the column to store the hash. Defaults to \"id\".</p> <code>'id'</code> <code>algorithm</code> <code>Callable[[bytes], HASH]</code> <p>The hashing algorithm to use. Defaults to hashlib.sha256.</p> <code>sha256</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The modified row (dictionary) with the SHA256 hash added.</p> Source code in <code>ratiopath/tiling/utils.py</code> <pre><code>def row_hash(\n    row: dict[str, Any],\n    column: str = \"id\",\n    algorithm: Callable[[bytes], hashlib._hashlib.HASH] = hashlib.sha256,  # type: ignore[name-defined]\n) -&gt; dict[str, Any]:\n    \"\"\"Hashes a row (dictionary) using SHA256 and adds the hash as a new column.\n\n    Args:\n        row: The dictionary (row) to hash.\n        column: The name of the column to store the hash. Defaults to \"id\".\n        algorithm: The hashing algorithm to use. Defaults to hashlib.sha256.\n\n    Returns:\n        The modified row (dictionary) with the SHA256 hash added.\n    \"\"\"\n    row[column] = algorithm(str(row).encode()).hexdigest()\n    return row\n</code></pre>"}]}